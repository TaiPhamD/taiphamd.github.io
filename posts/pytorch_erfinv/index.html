<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Peter Pham">
<meta name="dcterms.date" content="2023-07-19">

<title>taiphamd - The Inverse Error Function</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
if (typeof require !== 'undefined') {
require.undef("plotly");
requirejs.config({
    paths: {
        'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']
    }
});
require(['plotly'], function(Plotly) {
    window._Plotly = Plotly;
});
}
</script>


  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">taiphamd</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../pr.html" rel="" target="">
 <span class="menu-text">My Contributions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/taiphamd" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The Inverse Error Function</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">pytorch</div>
                <div class="quarto-category">metal api</div>
                <div class="quarto-category">macos</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Peter Pham </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 19, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="overview" class="level1">
<h1>Overview</h1>
<p>I happen to stumble upon a <a href="https://github.com/pytorch/pytorch/issues/86808">feature request</a> to implement the metal backend for the <span class="math inline">\(\operatorname{erf}^{-1}(x)\)</span> in Pytorch. I thought it would be a good exercise to implement it myself to get a better understanding of defining custom torch ops for the MPS backend. (There’s also <a href="https://github.com/pytorch/pytorch/issues/77764">list</a> of unimplemented torch ops for MPS)</p>
<section id="math" class="level2">
<h2 class="anchored" data-anchor-id="math">Math</h2>
<p>To work on the inverse error function, we first need an understanding of the error function. The error function is defined as:</p>
<p><span id="eq-eq1"><span class="math display">\[
\operatorname{erf}(x)=\frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^{2}} d t
\tag{1}\]</span></span></p>
<p>The error function maps a real number in the domain <span class="math inline">\((-\infty, \infty)\)</span> to a real number from <span class="math inline">\((-1, 1)\)</span>.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.erf(torch.tensor(x)).numpy()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># add y as erf(x) label</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.line(x<span class="op">=</span>x, y<span class="op">=</span>y, labels<span class="op">=</span>{<span class="st">"x"</span>: <span class="st">"x"</span>, <span class="st">"y"</span>: <span class="st">"erf(x)"</span>})</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">

<div>                            <div id="04199431-e474-42ae-b150-c0ddbf4642c8" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("04199431-e474-42ae-b150-c0ddbf4642c8")) {                    Plotly.newPlot(                        "04199431-e474-42ae-b150-c0ddbf4642c8",                        [{"hovertemplate":"x=%{x}<br>erf(x)=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[-5.0,-4.98998998998999,-4.97997997997998,-4.96996996996997,-4.95995995995996,-4.94994994994995,-4.93993993993994,-4.92992992992993,-4.91991991991992,-4.90990990990991,-4.8998998998999,-4.88988988988989,-4.87987987987988,-4.86986986986987,-4.85985985985986,-4.84984984984985,-4.83983983983984,-4.82982982982983,-4.81981981981982,-4.80980980980981,-4.7997997997998,-4.78978978978979,-4.77977977977978,-4.76976976976977,-4.75975975975976,-4.74974974974975,-4.73973973973974,-4.72972972972973,-4.71971971971972,-4.70970970970971,-4.6996996996997,-4.68968968968969,-4.67967967967968,-4.66966966966967,-4.65965965965966,-4.64964964964965,-4.63963963963964,-4.62962962962963,-4.61961961961962,-4.60960960960961,-4.5995995995996,-4.58958958958959,-4.57957957957958,-4.56956956956957,-4.55955955955956,-4.54954954954955,-4.53953953953954,-4.52952952952953,-4.51951951951952,-4.50950950950951,-4.4994994994995,-4.48948948948949,-4.47947947947948,-4.46946946946947,-4.45945945945946,-4.44944944944945,-4.43943943943944,-4.42942942942943,-4.41941941941942,-4.40940940940941,-4.3993993993994,-4.38938938938939,-4.37937937937938,-4.36936936936937,-4.35935935935936,-4.34934934934935,-4.33933933933934,-4.32932932932933,-4.31931931931932,-4.3093093093093096,-4.2992992992992995,-4.2892892892892895,-4.2792792792792795,-4.2692692692692695,-4.2592592592592595,-4.2492492492492495,-4.2392392392392395,-4.2292292292292295,-4.2192192192192195,-4.2092092092092095,-4.1991991991991995,-4.1891891891891895,-4.1791791791791795,-4.1691691691691695,-4.1591591591591595,-4.1491491491491495,-4.1391391391391394,-4.129129129129129,-4.119119119119119,-4.109109109109109,-4.099099099099099,-4.089089089089089,-4.079079079079079,-4.069069069069069,-4.059059059059059,-4.049049049049049,-4.039039039039039,-4.029029029029029,-4.019019019019019,-4.009009009009009,-3.998998998998999,-3.988988988988989,-3.978978978978979,-3.968968968968969,-3.958958958958959,-3.948948948948949,-3.938938938938939,-3.928928928928929,-3.918918918918919,-3.908908908908909,-3.898898898898899,-3.888888888888889,-3.878878878878879,-3.868868868868869,-3.858858858858859,-3.848848848848849,-3.838838838838839,-3.828828828828829,-3.818818818818819,-3.808808808808809,-3.798798798798799,-3.7887887887887888,-3.7787787787787788,-3.7687687687687688,-3.7587587587587588,-3.7487487487487487,-3.7387387387387387,-3.7287287287287287,-3.7187187187187187,-3.7087087087087087,-3.6986986986986987,-3.6886886886886887,-3.6786786786786787,-3.6686686686686687,-3.6586586586586587,-3.6486486486486487,-3.6386386386386387,-3.6286286286286287,-3.6186186186186187,-3.6086086086086087,-3.5985985985985987,-3.5885885885885886,-3.5785785785785786,-3.5685685685685686,-3.5585585585585586,-3.5485485485485486,-3.5385385385385386,-3.5285285285285286,-3.5185185185185186,-3.5085085085085086,-3.4984984984984986,-3.4884884884884886,-3.4784784784784786,-3.4684684684684686,-3.4584584584584586,-3.4484484484484486,-3.4384384384384385,-3.4284284284284285,-3.4184184184184185,-3.4084084084084085,-3.3983983983983985,-3.388388388388388,-3.378378378378378,-3.368368368368368,-3.358358358358358,-3.348348348348348,-3.338338338338338,-3.328328328328328,-3.318318318318318,-3.308308308308308,-3.298298298298298,-3.288288288288288,-3.278278278278278,-3.268268268268268,-3.258258258258258,-3.248248248248248,-3.238238238238238,-3.228228228228228,-3.218218218218218,-3.208208208208208,-3.198198198198198,-3.188188188188188,-3.178178178178178,-3.168168168168168,-3.158158158158158,-3.148148148148148,-3.138138138138138,-3.128128128128128,-3.118118118118118,-3.108108108108108,-3.098098098098098,-3.088088088088088,-3.078078078078078,-3.068068068068068,-3.058058058058058,-3.048048048048048,-3.038038038038038,-3.028028028028028,-3.018018018018018,-3.008008008008008,-2.997997997997998,-2.987987987987988,-2.977977977977978,-2.967967967967968,-2.957957957957958,-2.947947947947948,-2.937937937937938,-2.9279279279279278,-2.9179179179179178,-2.9079079079079078,-2.8978978978978978,-2.8878878878878878,-2.8778778778778777,-2.8678678678678677,-2.8578578578578577,-2.8478478478478477,-2.8378378378378377,-2.8278278278278277,-2.8178178178178177,-2.8078078078078077,-2.7977977977977977,-2.7877877877877877,-2.7777777777777777,-2.7677677677677677,-2.7577577577577577,-2.7477477477477477,-2.7377377377377377,-2.7277277277277276,-2.7177177177177176,-2.7077077077077076,-2.6976976976976976,-2.6876876876876876,-2.6776776776776776,-2.6676676676676676,-2.6576576576576576,-2.6476476476476476,-2.6376376376376376,-2.6276276276276276,-2.6176176176176176,-2.6076076076076076,-2.5975975975975976,-2.5875875875875876,-2.5775775775775776,-2.5675675675675675,-2.5575575575575575,-2.5475475475475475,-2.5375375375375375,-2.5275275275275275,-2.5175175175175175,-2.5075075075075075,-2.4974974974974975,-2.4874874874874875,-2.4774774774774775,-2.4674674674674675,-2.4574574574574575,-2.4474474474474475,-2.4374374374374375,-2.4274274274274275,-2.4174174174174174,-2.4074074074074074,-2.3973973973973974,-2.3873873873873874,-2.3773773773773774,-2.3673673673673674,-2.3573573573573574,-2.3473473473473474,-2.3373373373373374,-2.3273273273273274,-2.3173173173173174,-2.3073073073073074,-2.2972972972972974,-2.2872872872872874,-2.2772772772772774,-2.2672672672672673,-2.2572572572572573,-2.2472472472472473,-2.2372372372372373,-2.2272272272272273,-2.2172172172172173,-2.2072072072072073,-2.1971971971971973,-2.1871871871871873,-2.1771771771771773,-2.1671671671671673,-2.1571571571571573,-2.1471471471471473,-2.1371371371371373,-2.1271271271271273,-2.1171171171171173,-2.1071071071071072,-2.0970970970970972,-2.0870870870870872,-2.0770770770770772,-2.067067067067067,-2.057057057057057,-2.047047047047047,-2.037037037037037,-2.027027027027027,-2.017017017017017,-2.007007007007007,-1.9969969969969972,-1.9869869869869872,-1.9769769769769772,-1.9669669669669672,-1.9569569569569571,-1.9469469469469471,-1.9369369369369371,-1.9269269269269271,-1.9169169169169171,-1.9069069069069071,-1.8968968968968971,-1.886886886886887,-1.876876876876877,-1.866866866866867,-1.856856856856857,-1.846846846846847,-1.836836836836837,-1.826826826826827,-1.816816816816817,-1.806806806806807,-1.796796796796797,-1.7867867867867866,-1.7767767767767766,-1.7667667667667666,-1.7567567567567566,-1.7467467467467466,-1.7367367367367366,-1.7267267267267266,-1.7167167167167166,-1.7067067067067065,-1.6966966966966965,-1.6866866866866865,-1.6766766766766765,-1.6666666666666665,-1.6566566566566565,-1.6466466466466465,-1.6366366366366365,-1.6266266266266265,-1.6166166166166165,-1.6066066066066065,-1.5965965965965965,-1.5865865865865865,-1.5765765765765765,-1.5665665665665665,-1.5565565565565564,-1.5465465465465464,-1.5365365365365364,-1.5265265265265264,-1.5165165165165164,-1.5065065065065064,-1.4964964964964964,-1.4864864864864864,-1.4764764764764764,-1.4664664664664664,-1.4564564564564564,-1.4464464464464464,-1.4364364364364364,-1.4264264264264264,-1.4164164164164164,-1.4064064064064064,-1.3963963963963963,-1.3863863863863863,-1.3763763763763763,-1.3663663663663663,-1.3563563563563563,-1.3463463463463463,-1.3363363363363363,-1.3263263263263263,-1.3163163163163163,-1.3063063063063063,-1.2962962962962963,-1.2862862862862863,-1.2762762762762763,-1.2662662662662663,-1.2562562562562563,-1.2462462462462462,-1.2362362362362362,-1.2262262262262262,-1.2162162162162162,-1.2062062062062062,-1.1961961961961962,-1.1861861861861862,-1.1761761761761762,-1.1661661661661662,-1.1561561561561562,-1.1461461461461462,-1.1361361361361362,-1.1261261261261262,-1.1161161161161162,-1.1061061061061062,-1.0960960960960962,-1.0860860860860861,-1.0760760760760761,-1.0660660660660661,-1.0560560560560561,-1.0460460460460461,-1.0360360360360361,-1.026026026026026,-1.016016016016016,-1.006006006006006,-0.9959959959959956,-0.9859859859859856,-0.9759759759759756,-0.9659659659659656,-0.9559559559559556,-0.9459459459459456,-0.9359359359359356,-0.9259259259259256,-0.9159159159159156,-0.9059059059059056,-0.8958958958958956,-0.8858858858858856,-0.8758758758758756,-0.8658658658658656,-0.8558558558558556,-0.8458458458458455,-0.8358358358358355,-0.8258258258258255,-0.8158158158158155,-0.8058058058058055,-0.7957957957957955,-0.7857857857857855,-0.7757757757757755,-0.7657657657657655,-0.7557557557557555,-0.7457457457457455,-0.7357357357357355,-0.7257257257257255,-0.7157157157157155,-0.7057057057057055,-0.6956956956956954,-0.6856856856856854,-0.6756756756756754,-0.6656656656656654,-0.6556556556556554,-0.6456456456456454,-0.6356356356356354,-0.6256256256256254,-0.6156156156156154,-0.6056056056056054,-0.5955955955955954,-0.5855855855855854,-0.5755755755755754,-0.5655655655655654,-0.5555555555555554,-0.5455455455455454,-0.5355355355355353,-0.5255255255255253,-0.5155155155155153,-0.5055055055055053,-0.4954954954954953,-0.4854854854854853,-0.4754754754754753,-0.4654654654654653,-0.4554554554554553,-0.4454454454454453,-0.4354354354354353,-0.4254254254254253,-0.41541541541541527,-0.40540540540540526,-0.39539539539539525,-0.38538538538538525,-0.37537537537537524,-0.36536536536536524,-0.35535535535535523,-0.3453453453453452,-0.3353353353353352,-0.3253253253253252,-0.3153153153153152,-0.3053053053053052,-0.2952952952952952,-0.2852852852852852,-0.2752752752752752,-0.26526526526526517,-0.25525525525525516,-0.24524524524524516,-0.23523523523523515,-0.22522522522522515,-0.21521521521521514,-0.20520520520520513,-0.19519519519519513,-0.18518518518518512,-0.1751751751751751,-0.1651651651651651,-0.1551551551551551,-0.1451451451451451,-0.1351351351351351,-0.12512512512512508,-0.11511511511511507,-0.10510510510510507,-0.09509509509509506,-0.08508508508508505,-0.07507507507507505,-0.06506506506506504,-0.055055055055055035,-0.04504504504504503,-0.03503503503503502,-0.025025025025025016,-0.01501501501501501,-0.005005005005005003,0.005005005005005003,0.01501501501501501,0.025025025025025016,0.03503503503503502,0.04504504504504503,0.055055055055055035,0.06506506506506504,0.07507507507507505,0.08508508508508505,0.09509509509509506,0.10510510510510507,0.11511511511511507,0.12512512512512508,0.1351351351351351,0.1451451451451451,0.1551551551551551,0.1651651651651651,0.1751751751751751,0.18518518518518512,0.19519519519519513,0.20520520520520513,0.21521521521521514,0.22522522522522515,0.23523523523523515,0.24524524524524516,0.25525525525525516,0.26526526526526517,0.2752752752752752,0.2852852852852852,0.2952952952952952,0.3053053053053052,0.3153153153153152,0.3253253253253252,0.3353353353353352,0.3453453453453452,0.35535535535535523,0.36536536536536524,0.37537537537537524,0.38538538538538525,0.39539539539539525,0.40540540540540526,0.41541541541541527,0.4254254254254253,0.4354354354354353,0.4454454454454453,0.4554554554554553,0.4654654654654653,0.4754754754754753,0.4854854854854853,0.4954954954954953,0.5055055055055053,0.5155155155155153,0.5255255255255253,0.5355355355355353,0.5455455455455454,0.5555555555555554,0.5655655655655654,0.5755755755755754,0.5855855855855854,0.5955955955955954,0.6056056056056054,0.6156156156156154,0.6256256256256254,0.6356356356356354,0.6456456456456454,0.6556556556556554,0.6656656656656654,0.6756756756756754,0.6856856856856854,0.6956956956956954,0.7057057057057055,0.7157157157157155,0.7257257257257255,0.7357357357357355,0.7457457457457455,0.7557557557557555,0.7657657657657655,0.7757757757757755,0.7857857857857855,0.7957957957957955,0.8058058058058055,0.8158158158158155,0.8258258258258255,0.8358358358358355,0.8458458458458455,0.8558558558558556,0.8658658658658656,0.8758758758758756,0.8858858858858856,0.8958958958958956,0.9059059059059056,0.9159159159159156,0.9259259259259256,0.9359359359359356,0.9459459459459456,0.9559559559559556,0.9659659659659656,0.9759759759759756,0.9859859859859856,0.9959959959959956,1.0060060060060056,1.0160160160160157,1.0260260260260257,1.0360360360360357,1.0460460460460457,1.0560560560560557,1.0660660660660657,1.0760760760760757,1.0860860860860857,1.0960960960960957,1.1061061061061057,1.1161161161161157,1.1261261261261257,1.1361361361361357,1.1461461461461457,1.1561561561561557,1.1661661661661658,1.1761761761761758,1.1861861861861858,1.1961961961961958,1.2062062062062058,1.2162162162162158,1.2262262262262258,1.2362362362362358,1.2462462462462458,1.2562562562562558,1.2662662662662658,1.2762762762762758,1.2862862862862858,1.2962962962962958,1.3063063063063058,1.3163163163163158,1.3263263263263259,1.3363363363363359,1.3463463463463459,1.3563563563563559,1.3663663663663659,1.3763763763763759,1.386386386386386,1.396396396396396,1.406406406406406,1.4164164164164168,1.4264264264264268,1.4364364364364368,1.4464464464464468,1.4564564564564568,1.4664664664664668,1.4764764764764768,1.4864864864864868,1.4964964964964969,1.5065065065065069,1.5165165165165169,1.5265265265265269,1.5365365365365369,1.5465465465465469,1.556556556556557,1.566566566566567,1.576576576576577,1.586586586586587,1.596596596596597,1.606606606606607,1.616616616616617,1.626626626626627,1.636636636636637,1.646646646646647,1.656656656656657,1.666666666666667,1.676676676676677,1.686686686686687,1.696696696696697,1.706706706706707,1.716716716716717,1.726726726726727,1.736736736736737,1.746746746746747,1.756756756756757,1.766766766766767,1.776776776776777,1.786786786786787,1.796796796796797,1.806806806806807,1.816816816816817,1.826826826826827,1.836836836836837,1.846846846846847,1.856856856856857,1.866866866866867,1.876876876876877,1.886886886886887,1.8968968968968971,1.9069069069069071,1.9169169169169171,1.9269269269269271,1.9369369369369371,1.9469469469469471,1.9569569569569571,1.9669669669669672,1.9769769769769772,1.9869869869869872,1.9969969969969972,2.007007007007007,2.017017017017017,2.027027027027027,2.037037037037037,2.047047047047047,2.057057057057057,2.067067067067067,2.0770770770770772,2.0870870870870872,2.0970970970970972,2.1071071071071072,2.1171171171171173,2.1271271271271273,2.1371371371371373,2.1471471471471473,2.1571571571571573,2.1671671671671673,2.1771771771771773,2.1871871871871873,2.1971971971971973,2.2072072072072073,2.2172172172172173,2.2272272272272273,2.2372372372372373,2.2472472472472473,2.2572572572572573,2.2672672672672673,2.2772772772772774,2.2872872872872874,2.2972972972972974,2.3073073073073074,2.3173173173173174,2.3273273273273274,2.3373373373373374,2.3473473473473474,2.3573573573573574,2.3673673673673674,2.3773773773773774,2.3873873873873874,2.3973973973973974,2.4074074074074074,2.4174174174174174,2.4274274274274275,2.4374374374374375,2.4474474474474475,2.4574574574574575,2.4674674674674675,2.4774774774774775,2.4874874874874875,2.4974974974974975,2.5075075075075075,2.5175175175175175,2.5275275275275275,2.5375375375375375,2.5475475475475475,2.5575575575575575,2.5675675675675675,2.5775775775775776,2.5875875875875876,2.5975975975975976,2.6076076076076076,2.6176176176176176,2.6276276276276276,2.6376376376376376,2.6476476476476476,2.6576576576576576,2.6676676676676676,2.6776776776776776,2.6876876876876876,2.6976976976976976,2.7077077077077076,2.7177177177177176,2.7277277277277276,2.7377377377377377,2.7477477477477477,2.7577577577577577,2.7677677677677677,2.7777777777777777,2.7877877877877877,2.7977977977977977,2.8078078078078077,2.8178178178178177,2.8278278278278277,2.8378378378378377,2.8478478478478477,2.8578578578578577,2.8678678678678677,2.8778778778778777,2.8878878878878878,2.8978978978978978,2.9079079079079078,2.9179179179179178,2.9279279279279278,2.937937937937938,2.947947947947948,2.957957957957958,2.967967967967968,2.977977977977978,2.987987987987988,2.997997997997998,3.0080080080080087,3.0180180180180187,3.0280280280280287,3.0380380380380387,3.0480480480480487,3.0580580580580587,3.0680680680680688,3.0780780780780788,3.0880880880880888,3.0980980980980988,3.108108108108109,3.118118118118119,3.128128128128129,3.138138138138139,3.148148148148149,3.158158158158159,3.168168168168169,3.178178178178179,3.188188188188189,3.198198198198199,3.208208208208209,3.218218218218219,3.228228228228229,3.238238238238239,3.248248248248249,3.258258258258259,3.268268268268269,3.278278278278279,3.288288288288289,3.298298298298299,3.308308308308309,3.318318318318319,3.328328328328329,3.338338338338339,3.348348348348349,3.358358358358359,3.368368368368369,3.378378378378379,3.388388388388389,3.398398398398399,3.408408408408409,3.418418418418419,3.428428428428429,3.438438438438439,3.448448448448449,3.458458458458459,3.468468468468469,3.478478478478479,3.488488488488489,3.498498498498499,3.508508508508509,3.518518518518519,3.528528528528529,3.538538538538539,3.548548548548549,3.558558558558559,3.568568568568569,3.578578578578579,3.588588588588589,3.598598598598599,3.608608608608609,3.618618618618619,3.628628628628629,3.638638638638639,3.648648648648649,3.658658658658659,3.668668668668669,3.678678678678679,3.688688688688689,3.698698698698699,3.708708708708709,3.718718718718719,3.728728728728729,3.738738738738739,3.748748748748749,3.758758758758759,3.768768768768769,3.778778778778779,3.788788788788789,3.7987987987987992,3.8088088088088092,3.8188188188188192,3.8288288288288292,3.8388388388388393,3.8488488488488493,3.8588588588588593,3.8688688688688693,3.8788788788788793,3.8888888888888893,3.8988988988988993,3.9089089089089093,3.9189189189189193,3.9289289289289293,3.9389389389389393,3.9489489489489493,3.9589589589589593,3.9689689689689693,3.9789789789789793,3.9889889889889893,3.9989989989989994,4.009009009009009,4.019019019019019,4.029029029029029,4.039039039039039,4.049049049049049,4.059059059059059,4.069069069069069,4.079079079079079,4.089089089089089,4.099099099099099,4.109109109109109,4.119119119119119,4.129129129129129,4.1391391391391394,4.1491491491491495,4.1591591591591595,4.1691691691691695,4.1791791791791795,4.1891891891891895,4.1991991991991995,4.2092092092092095,4.2192192192192195,4.2292292292292295,4.2392392392392395,4.2492492492492495,4.2592592592592595,4.2692692692692695,4.2792792792792795,4.2892892892892895,4.2992992992992995,4.3093093093093096,4.31931931931932,4.32932932932933,4.33933933933934,4.34934934934935,4.35935935935936,4.36936936936937,4.37937937937938,4.38938938938939,4.3993993993994,4.40940940940941,4.41941941941942,4.42942942942943,4.43943943943944,4.44944944944945,4.45945945945946,4.46946946946947,4.47947947947948,4.48948948948949,4.4994994994995,4.50950950950951,4.51951951951952,4.52952952952953,4.53953953953954,4.54954954954955,4.55955955955956,4.56956956956957,4.57957957957958,4.58958958958959,4.5995995995996,4.60960960960961,4.61961961961962,4.62962962962963,4.63963963963964,4.64964964964965,4.65965965965966,4.66966966966967,4.67967967967968,4.68968968968969,4.6996996996997,4.70970970970971,4.71971971971972,4.72972972972973,4.73973973973974,4.74974974974975,4.75975975975976,4.76976976976977,4.77977977977978,4.78978978978979,4.7997997997998,4.80980980980981,4.81981981981982,4.82982982982983,4.83983983983984,4.84984984984985,4.85985985985986,4.86986986986987,4.87987987987988,4.88988988988989,4.8998998998999,4.90990990990991,4.91991991991992,4.92992992992993,4.93993993993994,4.94994994994995,4.95995995995996,4.96996996996997,4.97997997997998,4.98998998998999,5.0],"xaxis":"x","y":[-0.9999999999984626,-0.9999999999982976,-0.9999999999981153,-0.9999999999979139,-0.9999999999976914,-0.9999999999974456,-0.9999999999971743,-0.9999999999968747,-0.9999999999965441,-0.9999999999961793,-0.9999999999957768,-0.9999999999953328,-0.9999999999948432,-0.9999999999943033,-0.9999999999937081,-0.9999999999930521,-0.9999999999923292,-0.9999999999915328,-0.9999999999906555,-0.9999999999896894,-0.9999999999886255,-0.9999999999874545,-0.9999999999861655,-0.9999999999847471,-0.9999999999831866,-0.99999999998147,-0.9999999999795822,-0.9999999999775065,-0.9999999999752247,-0.9999999999727168,-0.9999999999699609,-0.9999999999669331,-0.9999999999636073,-0.9999999999599547,-0.9999999999559444,-0.9999999999515419,-0.9999999999467098,-0.9999999999414075,-0.9999999999355902,-0.9999999999292093,-0.9999999999222116,-0.9999999999145388,-0.9999999999061275,-0.9999999998969088,-0.999999999886807,-0.9999999998757395,-0.9999999998636168,-0.9999999998503406,-0.9999999998358045,-0.9999999998198916,-0.9999999998024753,-0.9999999997834175,-0.9999999997625673,-0.9999999997397611,-0.9999999997148199,-0.9999999996875498,-0.9999999996577391,-0.9999999996251576,-0.9999999995895549,-0.9999999995506588,-0.9999999995081729,-0.9999999994617754,-0.9999999994111162,-0.9999999993558151,-0.9999999992954587,-0.999999999229598,-0.9999999991577457,-0.9999999990793723,-0.999999998993903,-0.9999999989007142,-0.9999999987991288,-0.9999999986884127,-0.9999999985677692,-0.9999999984363346,-0.9999999982931722,-0.9999999981372669,-0.9999999979675187,-0.9999999977827352,-0.9999999975816249,-0.9999999973627893,-0.999999997124714,-0.999999996865759,-0.9999999965841497,-0.9999999962779658,-0.9999999959451291,-0.9999999955833925,-0.9999999951903249,-0.9999999947632985,-0.9999999942994726,-0.9999999937957764,-0.9999999932488928,-0.9999999926552376,-0.9999999920109397,-0.9999999913118194,-0.9999999905533636,-0.9999999897307017,-0.9999999888385767,-0.9999999878713175,-0.9999999868228064,-0.999999985686446,-0.9999999844551224,-0.9999999831211671,-0.9999999816763154,-0.9999999801116616,-0.9999999784176116,-0.9999999765838319,-0.999999974599195,-0.999999972451721,-0.9999999701285148,-0.9999999676156996,-0.999999964898345,-0.9999999619603905,-0.999999958784564,-0.999999955352294,-0.9999999516436163,-0.9999999476370743,-0.9999999433096121,-0.9999999386364609,-0.9999999335910174,-0.9999999281447138,-0.9999999222668801,-0.9999999159245956,-0.9999999090825319,-0.9999999017027847,-0.9999998937446956,-0.9999998851646597,-0.9999998759159239,-0.9999998659483696,-0.9999998552082823,-0.9999998436381057,-0.9999998311761809,-0.9999998177564675,-0.9999998033082484,-0.9999997877558147,-0.99999977101813,-0.9999997530084761,-0.9999997336340736,-0.9999997127956799,-0.999999690387162,-0.9999996662950436,-0.999999640398022,-0.999999612566458,-0.9999995826618318,-0.9999995505361678,-0.9999995160314236,-0.999999478978841,-0.9999994391982598,-0.9999993964973892,-0.9999993506710351,-0.9999993015002829,-0.999999248751631,-0.9999991921760729,-0.9999991315081262,-0.999999066464804,-0.9999989967445269,-0.9999989220259726,-0.9999988419668577,-0.9999987562026502,-0.9999986643452098,-0.999998565981348,-0.9999984606713099,-0.9999983479471681,-0.9999982273111279,-0.9999980982337368,-0.9999979601519964,-0.9999978124673682,-0.9999976545436704,-0.9999974857048598,-0.9999973052326935,-0.9999971123642623,-0.9999969062893932,-0.9999966861479109,-0.9999964510267549,-0.999996199956942,-0.9999959319103697,-0.9999956457964507,-0.9999953404585733,-0.9999950146703755,-0.9999946671318288,-0.9999942964651193,-0.9999939012103185,-0.9999934798208352,-0.999993030658635,-0.9999925519892219,-0.9999920419763678,-0.9999914986765799,-0.9999909200332948,-0.9999903038707878,-0.9999896478877832,-0.9999889496507559,-0.9999882065869083,-0.9999874159768105,-0.9999865749466883,-0.9999856804603481,-0.9999847293107175,-0.9999837181109923,-0.9999826432853699,-0.9999815010593547,-0.9999802874496171,-0.9999789982533893,-0.9999776290373803,-0.9999761751261902,-0.9999746315902063,-0.9999729932329593,-0.9999712545779225,-0.9999694098547288,-0.9999674529847893,-0.9999653775662871,-0.9999631768585262,-0.9999608437656133,-0.9999583708194462,-0.9999557501619861,-0.9999529735267911,-0.9999500322197814,-0.9999469170992136,-0.9999436185548369,-0.9999401264862043,-0.9999364302801101,-0.9999325187871282,-0.9999283802972191,-0.999924002514381,-0.9999193725303112,-0.9999144767970499,-0.999909301098576,-0.9999038305213227,-0.9998980494235818,-0.9998919414037666,-0.9998854892674969,-0.9998786749934793,-0.9998714796981432,-0.9998638835990055,-0.9998558659767247,-0.999847405135815,-0.9998384783639834,-0.9998290618900566,-0.9998191308404625,-0.9998086591942328,-0.9997976197364911,-0.9997859840103916,-0.9997737222674747,-0.9997608034164036,-0.9997471949700483,-0.9997328629908828,-0.9997177720346606,-0.9997018850923352,-0.9996851635301922,-0.9996675670281602,-0.9996490535162676,-0.9996295791092137,-0.9996090980390229,-0.9995875625857515,-0.9995649230062176,-0.9995411274607238,-0.9995161219377491,-0.9994898501765772,-0.9994622535878414,-0.9994332711719583,-0.9994028394354293,-0.9993708923049867,-0.9993373610395668,-0.9993021741400914,-0.999265257257038,-0.9992265330957903,-0.999185921319752,-0.9991433384512145,-0.9990986977699723,-0.9990519092096782,-0.9990028792519379,-0.9989515108181402,-0.9988977031590278,-0.9988413517420142,-0.998782348136251,-0.998720579895463,-0.9986559304385607,-0.9985882789280498,-0.9985175001462623,-0.9984434643694288,-0.998366037239627,-0.998285079634636,-0.9982004475357341,-0.9981119918934838,-0.9980195584915461,-0.9979229878085788,-0.9978221148782694,-0.9977167691475664,-0.9976067743331705,-0.9974919482763569,-0.997372102796204,-0.9972470435413069,-0.997116569840062,-0.9969804745496145,-0.9968385439035635,-0.9966905573585287,-0.9965362874396853,-0.9963754995853821,-0.9962079519909623,-0.9960333954519124,-0.9958515732064724,-0.9956622207778454,-0.9954650658161498,-0.9952598279402676,-0.9950462185797442,-0.9948239408169031,-0.9945926892293487,-0.9943521497330297,-0.9941019994260492,-0.9938419064334107,-0.9935715297528955,-0.9932905191022732,-0.9929985147680562,-0.9926951474560135,-0.9923800381436623,-0.9920527979349694,-0.9917130279174944,-0.9913603190222138,-0.9909942518862749,-0.9906143967189284,-0.9902203131708998,-0.9898115502074609,-0.9893876459854716,-0.9889481277346628,-0.9884925116434442,-0.9880203027495145,-0.9875309948355666,-0.9870240703303786,-0.9864990002155863,-0.9859552439384385,-0.9853922493308387,-0.9848094525349798,-0.9842062779358811,-0.9835821381011413,-0.9829364337282194,-0.9822685535995636,-0.981577874545901,-0.9808637614180109,-0.9801255670672984,-0.9793626323354879,-0.978574286053757,-0.9777598450516265,-0.9769186141759258,-0.9760498863201472,-0.9751529424645033,-0.9742270517269959,-0.9732714714258051,-0.9722854471533007,-0.9712682128619742,-0.9702189909625849,-0.9691369924348089,-0.9680214169506713,-0.9668714530110389,-0.9656862780954392,-0.9644650588254648,-0.9632069511420186,-0.9619111004966355,-0.9605766420571188,-0.9592027009277084,-0.9577883923839949,-0.9563328221227752,-0.9548350865270392,-0.9532942729462601,-0.9517094599921468,-0.9500797178500064,-0.9484041086058467,-0.9466816865893339,-0.9449114987327061,-0.9430925849457237,-0.9412239785067233,-0.9393047064698237,-0.9373337900883102,-0.9353102452542124,-0.9332330829540616,-0.9311013097408025,-0.9289139282218081,-0.926669937562927,-0.9243683340084743,-0.922008111417048,-0.9195882618130395,-0.9171077759536774,-0.9145656439114246,-0.9119608556715229,-0.9092924017444587,-0.9065592737930963,-0.9037604652742045,-0.9008949720940742,-0.8979617932779045,-0.8949599316526069,-0.8918883945426543,-0.8887461944785757,-0.8855323499176738,-0.8822458859765179,-0.8788858351747392,-0.8754512381896309,-0.8719411446210334,-0.8683546137659572,-0.8646907154023742,-0.8609485305815859,-0.8571271524285504,-0.8532256869495289,-0.84924325384639,-0.8451789873368877,-0.8410320369802069,-0.8368015685070517,-0.8324867646535241,-0.8280868259980332,-0.8236009718004431,-0.8190284408426574,-0.8143684922698179,-0.8096204064312782,-0.8047834857204978,-0.7998570554129861,-0.7948404645014131,-0.7897330865269884,-0.7845343204062023,-0.7792435912520039,-0.7738603511884913,-0.7683840801581716,-0.7628142867208454,-0.7571505088431635,-0.7513923146778961,-0.7455393033319553,-0.7395911056222032,-0.7335473848180823,-0.7274078373701023,-0.7211721936232168,-0.7148402185141319,-0.7084117122515865,-0.7018865109786545,-0.6952644874161243,-0.6885455514860186,-0.681729650914329,-0.6748167718120529,-0.6678069392336266,-0.6607002177118723,-0.6534967117685838,-0.6461965663998988,-0.6387999675356208,-0.6313071424716782,-0.623718360274921,-0.6160339321594916,-0.608254211834018,-0.6003795958189103,-0.5924105237330685,-0.584347478549332,-0.5761909868180424,-0.567941618858107,-0.5595999889149967,-0.551166755285137,-0.5426426204061858,-0.5340283309127336,-0.5253246776569884,-0.5165324956940553,-0.5076526642314513,-0.49868610654254064,-0.4896337898436152,-0.4804967251343818,-0.47127596700166724,-0.4619726133861877,-0.4525878053122769,-0.44312272658050866,-0.43357860342319454,-0.42395670412278236,-0.41425833859322597,-0.4044848579244412,-0.39463765389000965,-0.3847181584183376,-0.3747278430275216,-0.3646682182242189,-0.3545408328668678,-0.3443472734936453,-0.3340891636155988,-0.3237681629754285,-0.313385966772447,-0.3029443048542835,-0.2924449408759425,-0.28188967142687493,-0.27128032512675554,-0.26061876169070697,-0.24990687096474964,-0.23914657193229527,-0.22833981169254447,-0.21748856441168182,-0.20659483024780345,-0.19566063425054445,-0.18468802523640918,-0.1736790746408411,-0.16263587534809967,-0.1515605405000433,-0.14045520228494526,-0.12932201070749832,-0.11816313234118857,-0.10698074906424467,-0.09577705678039006,-0.08455426412564805,-0.07331459116246869,-0.06206026806246342,-0.05079353377905072,-0.03951663471132844,-0.028231823360502166,-0.016941356980208693,-0.005647496222082211,0.005647496222082211,0.016941356980208693,0.028231823360502166,0.03951663471132844,0.05079353377905072,0.06206026806246342,0.07331459116246869,0.08455426412564805,0.09577705678039006,0.10698074906424467,0.11816313234118857,0.12932201070749832,0.14045520228494526,0.1515605405000433,0.16263587534809967,0.1736790746408411,0.18468802523640918,0.19566063425054445,0.20659483024780345,0.21748856441168182,0.22833981169254447,0.23914657193229527,0.24990687096474964,0.26061876169070697,0.27128032512675554,0.28188967142687493,0.2924449408759425,0.3029443048542835,0.313385966772447,0.3237681629754285,0.3340891636155988,0.3443472734936453,0.3545408328668678,0.3646682182242189,0.3747278430275216,0.3847181584183376,0.39463765389000965,0.4044848579244412,0.41425833859322597,0.42395670412278236,0.43357860342319454,0.44312272658050866,0.4525878053122769,0.4619726133861877,0.47127596700166724,0.4804967251343818,0.4896337898436152,0.49868610654254064,0.5076526642314513,0.5165324956940553,0.5253246776569884,0.5340283309127336,0.5426426204061858,0.551166755285137,0.5595999889149967,0.567941618858107,0.5761909868180424,0.584347478549332,0.5924105237330685,0.6003795958189103,0.608254211834018,0.6160339321594916,0.623718360274921,0.6313071424716782,0.6387999675356208,0.6461965663998988,0.6534967117685838,0.6607002177118723,0.6678069392336266,0.6748167718120529,0.681729650914329,0.6885455514860186,0.6952644874161243,0.7018865109786545,0.7084117122515865,0.7148402185141319,0.7211721936232168,0.7274078373701023,0.7335473848180823,0.7395911056222032,0.7455393033319553,0.7513923146778961,0.7571505088431635,0.7628142867208454,0.7683840801581716,0.7738603511884913,0.7792435912520039,0.7845343204062023,0.7897330865269884,0.7948404645014131,0.7998570554129861,0.8047834857204978,0.8096204064312782,0.8143684922698179,0.8190284408426574,0.8236009718004431,0.8280868259980332,0.8324867646535241,0.8368015685070517,0.8410320369802069,0.8451789873368876,0.8492432538463899,0.8532256869495287,0.8571271524285503,0.8609485305815857,0.864690715402374,0.8683546137659571,0.8719411446210333,0.8754512381896307,0.878885835174739,0.8822458859765178,0.8855323499176737,0.8887461944785756,0.8918883945426542,0.8949599316526068,0.8979617932779043,0.900894972094074,0.9037604652742044,0.9065592737930963,0.9092924017444586,0.9119608556715229,0.9145656439114245,0.9171077759536773,0.9195882618130394,0.922008111417048,0.9243683340084743,0.926669937562927,0.928913928221808,0.9311013097408025,0.9332330829540616,0.9353102452542124,0.9373337900883101,0.9393047064698236,0.9412239785067233,0.9430925849457237,0.9449114987327061,0.9466816865893338,0.9484041086058466,0.9500797178500063,0.9517094599921467,0.95329427294626,0.9548350865270392,0.9563328221227752,0.9577883923839949,0.9592027009277085,0.9605766420571189,0.9619111004966356,0.9632069511420187,0.964465058825465,0.9656862780954392,0.966871453011039,0.9680214169506713,0.9691369924348089,0.970218990962585,0.9712682128619743,0.9722854471533007,0.9732714714258051,0.974227051726996,0.9751529424645033,0.9760498863201473,0.9769186141759258,0.9777598450516265,0.978574286053757,0.9793626323354879,0.9801255670672984,0.9808637614180109,0.981577874545901,0.9822685535995637,0.9829364337282194,0.9835821381011413,0.9842062779358812,0.9848094525349799,0.9853922493308387,0.9859552439384385,0.9864990002155863,0.9870240703303788,0.9875309948355666,0.9880203027495145,0.9884925116434442,0.9889481277346628,0.9893876459854716,0.9898115502074609,0.9902203131708998,0.9906143967189284,0.9909942518862749,0.9913603190222138,0.9917130279174944,0.9920527979349694,0.9923800381436623,0.9926951474560135,0.9929985147680562,0.9932905191022732,0.9935715297528955,0.9938419064334107,0.9941019994260492,0.9943521497330297,0.9945926892293487,0.9948239408169031,0.9950462185797442,0.9952598279402676,0.9954650658161498,0.9956622207778454,0.9958515732064724,0.9960333954519124,0.9962079519909623,0.9963754995853821,0.9965362874396853,0.9966905573585287,0.9968385439035635,0.9969804745496145,0.997116569840062,0.9972470435413069,0.997372102796204,0.9974919482763569,0.9976067743331705,0.9977167691475664,0.9978221148782694,0.9979229878085788,0.9980195584915461,0.9981119918934838,0.9982004475357341,0.998285079634636,0.998366037239627,0.9984434643694288,0.9985175001462623,0.9985882789280498,0.9986559304385607,0.998720579895463,0.998782348136251,0.9988413517420142,0.9988977031590278,0.9989515108181402,0.9990028792519379,0.9990519092096782,0.9990986977699723,0.9991433384512145,0.999185921319752,0.9992265330957903,0.999265257257038,0.9993021741400914,0.9993373610395668,0.9993708923049867,0.9994028394354293,0.9994332711719583,0.9994622535878414,0.9994898501765772,0.9995161219377491,0.9995411274607238,0.9995649230062176,0.9995875625857515,0.9996090980390229,0.9996295791092137,0.9996490535162676,0.9996675670281602,0.9996851635301922,0.9997018850923352,0.9997177720346606,0.9997328629908828,0.9997471949700483,0.9997608034164036,0.9997737222674747,0.9997859840103916,0.9997976197364911,0.9998086591942328,0.9998191308404625,0.9998290618900566,0.9998384783639834,0.999847405135815,0.9998558659767247,0.9998638835990055,0.9998714796981432,0.9998786749934793,0.9998854892674969,0.9998919414037666,0.9998980494235818,0.9999038305213227,0.999909301098576,0.9999144767970499,0.9999193725303112,0.999924002514381,0.9999283802972191,0.9999325187871282,0.9999364302801101,0.9999401264862043,0.9999436185548369,0.9999469170992136,0.9999500322197814,0.9999529735267911,0.9999557501619861,0.9999583708194462,0.9999608437656133,0.9999631768585262,0.9999653775662871,0.9999674529847893,0.9999694098547288,0.9999712545779225,0.9999729932329593,0.9999746315902063,0.9999761751261902,0.9999776290373803,0.9999789982533893,0.9999802874496171,0.9999815010593547,0.9999826432853699,0.9999837181109923,0.9999847293107175,0.9999856804603481,0.9999865749466883,0.9999874159768105,0.9999882065869083,0.9999889496507559,0.9999896478877832,0.9999903038707878,0.9999909200332948,0.9999914986765799,0.9999920419763678,0.9999925519892219,0.999993030658635,0.9999934798208352,0.9999939012103185,0.9999942964651193,0.9999946671318288,0.9999950146703755,0.9999953404585733,0.9999956457964507,0.9999959319103697,0.999996199956942,0.9999964510267549,0.9999966861479109,0.9999969062893932,0.9999971123642623,0.9999973052326935,0.9999974857048598,0.9999976545436704,0.9999978124673682,0.9999979601519964,0.9999980982337368,0.9999982273111279,0.9999983479471681,0.9999984606713099,0.999998565981348,0.9999986643452098,0.9999987562026502,0.9999988419668577,0.9999989220259726,0.9999989967445269,0.999999066464804,0.9999991315081262,0.9999991921760729,0.999999248751631,0.9999993015002829,0.9999993506710351,0.9999993964973892,0.9999994391982598,0.999999478978841,0.9999995160314236,0.9999995505361678,0.9999995826618318,0.999999612566458,0.999999640398022,0.9999996662950436,0.999999690387162,0.9999997127956799,0.9999997336340736,0.9999997530084761,0.99999977101813,0.9999997877558147,0.9999998033082484,0.9999998177564675,0.9999998311761809,0.9999998436381057,0.9999998552082823,0.9999998659483696,0.9999998759159239,0.9999998851646597,0.9999998937446956,0.9999999017027847,0.9999999090825319,0.9999999159245956,0.9999999222668801,0.9999999281447138,0.9999999335910174,0.9999999386364609,0.9999999433096121,0.9999999476370743,0.9999999516436163,0.999999955352294,0.999999958784564,0.9999999619603905,0.999999964898345,0.9999999676156996,0.9999999701285148,0.999999972451721,0.999999974599195,0.9999999765838319,0.9999999784176116,0.9999999801116616,0.9999999816763154,0.9999999831211671,0.9999999844551224,0.999999985686446,0.9999999868228064,0.9999999878713175,0.9999999888385767,0.9999999897307017,0.9999999905533636,0.9999999913118194,0.9999999920109397,0.9999999926552376,0.9999999932488928,0.9999999937957764,0.9999999942994726,0.9999999947632985,0.9999999951903249,0.9999999955833925,0.9999999959451291,0.9999999962779658,0.9999999965841497,0.999999996865759,0.999999997124714,0.9999999973627893,0.9999999975816249,0.9999999977827352,0.9999999979675187,0.9999999981372669,0.9999999982931722,0.9999999984363346,0.9999999985677692,0.9999999986884127,0.9999999987991288,0.9999999989007142,0.999999998993903,0.9999999990793723,0.9999999991577457,0.999999999229598,0.9999999992954587,0.9999999993558151,0.9999999994111162,0.9999999994617754,0.9999999995081729,0.9999999995506588,0.9999999995895549,0.9999999996251576,0.9999999996577391,0.9999999996875498,0.9999999997148199,0.9999999997397611,0.9999999997625673,0.9999999997834175,0.9999999998024753,0.9999999998198916,0.9999999998358045,0.9999999998503406,0.9999999998636168,0.9999999998757395,0.999999999886807,0.9999999998969088,0.9999999999061275,0.9999999999145388,0.9999999999222116,0.9999999999292093,0.9999999999355902,0.9999999999414075,0.9999999999467098,0.9999999999515419,0.9999999999559444,0.9999999999599547,0.9999999999636073,0.9999999999669331,0.9999999999699609,0.9999999999727168,0.9999999999752247,0.9999999999775065,0.9999999999795822,0.99999999998147,0.9999999999831866,0.9999999999847471,0.9999999999861655,0.9999999999874545,0.9999999999886255,0.9999999999896894,0.9999999999906555,0.9999999999915328,0.9999999999923292,0.9999999999930521,0.9999999999937081,0.9999999999943033,0.9999999999948432,0.9999999999953328,0.9999999999957768,0.9999999999961793,0.9999999999965441,0.9999999999968747,0.9999999999971743,0.9999999999974456,0.9999999999976914,0.9999999999979139,0.9999999999981153,0.9999999999982976,0.9999999999984626],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"x"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"erf(x)"}},"legend":{"tracegroupgap":0},"margin":{"t":60}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('04199431-e474-42ae-b150-c0ddbf4642c8');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>The inverse error function is defined as: <span id="eq-eq2"><span class="math display">\[
\operatorname{erf}^{-1}(\operatorname{erf}(x))=x
\tag{2}\]</span></span></p>
<p>This means the <span class="math inline">\(\operatorname{erf}^{-1}(x)\)</span> will have a domain of <span class="math inline">\((-1, 1)\)</span> and a range of <span class="math inline">\((-\infty, \infty)\)</span>.</p>
<p>There is no closed-form solution for the <span class="math inline">\(\operatorname{erf}^{-1}(x)\)</span> however it can be approximated using elementary function as proposed by Abramowitz and Stegun<span class="citation" data-cites="educare_error_in_functions">[<a href="#ref-educare_error_in_functions" role="doc-biblioref">1</a>]</span>. The approximation is given by:</p>
<p><span id="eq-eq3"><span class="math display">\[
\operatorname{erf}^{-1}(x) \approx \operatorname{sgn}(x) \sqrt{\sqrt{\left(\frac{2}{\pi a}+\frac{\ln(1-x^{2})}{2}\right)^{2}-  \frac{\ln (1-x^{2})}{a}   }- (\frac{2}{\pi a}+\frac{\ln (1-x^{2})}{2})}
\tag{3}\]</span></span></p>
<p>where <span class="math inline">\(a=0.147\)</span> or <span class="math inline">\(a=0.140012\)</span> where the latter is more accurate around <span class="math inline">\(x=0\)</span> for the error function but the former has a smaller maximum error for the error function. There was no analysis given for the maximum error rate of the <span class="math inline">\(\operatorname{erf}^{-1}(x)\)</span> so I will have to experiment with it myself.</p>
<p>Here is a plot of the <span class="math inline">\(\operatorname{erf}^{-1}(x)\)</span> using the approximation method.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> erfinv(x, a<span class="op">=</span><span class="fl">0.147</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute the inverse error function using an approximation method</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the Abravov fast approximation method</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the first term</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    term <span class="op">=</span> np.sqrt(</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        np.sqrt(</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            (<span class="dv">2</span> <span class="op">/</span> (np.pi <span class="op">*</span> a) <span class="op">+</span> np.log(<span class="dv">1</span> <span class="op">-</span> x<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>) <span class="op">**</span> <span class="dv">2</span> <span class="op">-</span> np.log(<span class="dv">1</span> <span class="op">-</span> x<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> a</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="op">-</span> (<span class="dv">2</span> <span class="op">/</span> (np.pi <span class="op">*</span> a) <span class="op">+</span> np.log(<span class="dv">1</span> <span class="op">-</span> x<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the sign</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    sign <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span>  sign <span class="op">*</span> term</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorize the erfinv function</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>erfinv_vec <span class="op">=</span> np.vectorize(erfinv)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>y_rapid <span class="op">=</span> erfinv_vec(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add y as erfinv(x) label</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.line(x<span class="op">=</span>x, y<span class="op">=</span>y_rapid, labels<span class="op">=</span>{<span class="st">"x"</span>: <span class="st">"x"</span>, <span class="st">"y"</span>: <span class="st">"erfinv(x)"</span>})</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">

<div>                            <div id="3715238d-8b3f-4eeb-8315-1def10226f99" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("3715238d-8b3f-4eeb-8315-1def10226f99")) {                    Plotly.newPlot(                        "3715238d-8b3f-4eeb-8315-1def10226f99",                        [{"hovertemplate":"x=%{x}<br>erfinv(x)=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[-1.0,-0.997997997997998,-0.995995995995996,-0.993993993993994,-0.991991991991992,-0.98998998998999,-0.987987987987988,-0.985985985985986,-0.983983983983984,-0.9819819819819819,-0.97997997997998,-0.977977977977978,-0.975975975975976,-0.973973973973974,-0.9719719719719719,-0.96996996996997,-0.967967967967968,-0.965965965965966,-0.963963963963964,-0.9619619619619619,-0.95995995995996,-0.957957957957958,-0.955955955955956,-0.953953953953954,-0.9519519519519519,-0.94994994994995,-0.9479479479479479,-0.9459459459459459,-0.943943943943944,-0.9419419419419419,-0.93993993993994,-0.9379379379379379,-0.9359359359359359,-0.933933933933934,-0.9319319319319319,-0.92992992992993,-0.9279279279279279,-0.9259259259259259,-0.9239239239239239,-0.9219219219219219,-0.91991991991992,-0.9179179179179179,-0.9159159159159159,-0.9139139139139139,-0.9119119119119119,-0.9099099099099099,-0.9079079079079079,-0.9059059059059059,-0.9039039039039038,-0.9019019019019019,-0.8998998998998999,-0.8978978978978979,-0.8958958958958959,-0.8938938938938938,-0.8918918918918919,-0.8898898898898899,-0.8878878878878879,-0.8858858858858859,-0.8838838838838838,-0.8818818818818819,-0.8798798798798799,-0.8778778778778779,-0.8758758758758759,-0.8738738738738738,-0.8718718718718719,-0.8698698698698699,-0.8678678678678678,-0.8658658658658659,-0.8638638638638638,-0.8618618618618619,-0.8598598598598599,-0.8578578578578578,-0.8558558558558559,-0.8538538538538538,-0.8518518518518519,-0.8498498498498499,-0.8478478478478478,-0.8458458458458459,-0.8438438438438438,-0.8418418418418419,-0.8398398398398399,-0.8378378378378378,-0.8358358358358359,-0.8338338338338338,-0.8318318318318318,-0.8298298298298299,-0.8278278278278278,-0.8258258258258259,-0.8238238238238238,-0.8218218218218218,-0.8198198198198199,-0.8178178178178178,-0.8158158158158157,-0.8138138138138138,-0.8118118118118118,-0.8098098098098099,-0.8078078078078078,-0.8058058058058057,-0.8038038038038038,-0.8018018018018018,-0.7997997997997999,-0.7977977977977978,-0.7957957957957957,-0.7937937937937938,-0.7917917917917918,-0.7897897897897898,-0.7877877877877878,-0.7857857857857857,-0.7837837837837838,-0.7817817817817818,-0.7797797797797797,-0.7777777777777778,-0.7757757757757757,-0.7737737737737738,-0.7717717717717718,-0.7697697697697697,-0.7677677677677678,-0.7657657657657657,-0.7637637637637638,-0.7617617617617618,-0.7597597597597597,-0.7577577577577578,-0.7557557557557557,-0.7537537537537538,-0.7517517517517518,-0.7497497497497497,-0.7477477477477478,-0.7457457457457457,-0.7437437437437437,-0.7417417417417418,-0.7397397397397397,-0.7377377377377378,-0.7357357357357357,-0.7337337337337337,-0.7317317317317318,-0.7297297297297297,-0.7277277277277278,-0.7257257257257257,-0.7237237237237237,-0.7217217217217218,-0.7197197197197197,-0.7177177177177176,-0.7157157157157157,-0.7137137137137137,-0.7117117117117118,-0.7097097097097097,-0.7077077077077076,-0.7057057057057057,-0.7037037037037037,-0.7017017017017018,-0.6996996996996997,-0.6976976976976976,-0.6956956956956957,-0.6936936936936937,-0.6916916916916918,-0.6896896896896897,-0.6876876876876876,-0.6856856856856857,-0.6836836836836837,-0.6816816816816818,-0.6796796796796797,-0.6776776776776776,-0.6756756756756757,-0.6736736736736737,-0.6716716716716717,-0.6696696696696697,-0.6676676676676676,-0.6656656656656657,-0.6636636636636637,-0.6616616616616617,-0.6596596596596597,-0.6576576576576576,-0.6556556556556556,-0.6536536536536537,-0.6516516516516517,-0.6496496496496497,-0.6476476476476476,-0.6456456456456456,-0.6436436436436437,-0.6416416416416417,-0.6396396396396397,-0.6376376376376376,-0.6356356356356356,-0.6336336336336337,-0.6316316316316316,-0.6296296296296297,-0.6276276276276276,-0.6256256256256256,-0.6236236236236237,-0.6216216216216216,-0.6196196196196196,-0.6176176176176176,-0.6156156156156156,-0.6136136136136137,-0.6116116116116116,-0.6096096096096096,-0.6076076076076076,-0.6056056056056056,-0.6036036036036037,-0.6016016016016016,-0.5995995995995996,-0.5975975975975976,-0.5955955955955956,-0.5935935935935936,-0.5915915915915916,-0.5895895895895895,-0.5875875875875876,-0.5855855855855856,-0.5835835835835836,-0.5815815815815816,-0.5795795795795795,-0.5775775775775776,-0.5755755755755756,-0.5735735735735736,-0.5715715715715716,-0.5695695695695695,-0.5675675675675675,-0.5655655655655656,-0.5635635635635636,-0.5615615615615616,-0.5595595595595595,-0.5575575575575575,-0.5555555555555556,-0.5535535535535536,-0.5515515515515516,-0.5495495495495495,-0.5475475475475475,-0.5455455455455456,-0.5435435435435436,-0.5415415415415415,-0.5395395395395395,-0.5375375375375375,-0.5355355355355356,-0.5335335335335336,-0.5315315315315315,-0.5295295295295295,-0.5275275275275275,-0.5255255255255256,-0.5235235235235236,-0.5215215215215215,-0.5195195195195195,-0.5175175175175175,-0.5155155155155156,-0.5135135135135136,-0.5115115115115115,-0.5095095095095095,-0.5075075075075075,-0.5055055055055055,-0.5035035035035035,-0.5015015015015015,-0.49949949949949946,-0.4974974974974975,-0.49549549549549554,-0.4934934934934935,-0.4914914914914915,-0.48948948948948945,-0.4874874874874875,-0.48548548548548554,-0.48348348348348347,-0.4814814814814815,-0.47947947947947944,-0.4774774774774775,-0.47547547547547553,-0.47347347347347346,-0.4714714714714715,-0.46946946946946944,-0.4674674674674675,-0.4654654654654655,-0.46346346346346345,-0.4614614614614615,-0.45945945945945943,-0.4574574574574575,-0.4554554554554555,-0.45345345345345345,-0.4514514514514515,-0.4494494494494494,-0.44744744744744747,-0.4454454454454454,-0.44344344344344344,-0.4414414414414415,-0.4394394394394394,-0.43743743743743746,-0.4354354354354354,-0.43343343343343343,-0.4314314314314315,-0.4294294294294294,-0.42742742742742745,-0.4254254254254254,-0.42342342342342343,-0.42142142142142147,-0.4194194194194194,-0.41741741741741745,-0.4154154154154154,-0.4134134134134134,-0.41141141141141147,-0.4094094094094094,-0.40740740740740744,-0.4054054054054054,-0.4034034034034034,-0.40140140140140146,-0.3993993993993994,-0.39739739739739743,-0.39539539539539537,-0.3933933933933934,-0.39139139139139134,-0.3893893893893894,-0.3873873873873874,-0.38538538538538536,-0.3833833833833834,-0.38138138138138133,-0.3793793793793794,-0.3773773773773774,-0.37537537537537535,-0.3733733733733734,-0.37137137137137133,-0.36936936936936937,-0.3673673673673674,-0.36536536536536535,-0.3633633633633634,-0.3613613613613613,-0.35935935935935936,-0.3573573573573574,-0.35535535535535534,-0.3533533533533534,-0.3513513513513513,-0.34934934934934936,-0.3473473473473474,-0.34534534534534533,-0.3433433433433434,-0.3413413413413413,-0.33933933933933935,-0.3373373373373374,-0.3353353353353353,-0.33333333333333337,-0.3313313313313313,-0.32932932932932935,-0.3273273273273274,-0.3253253253253253,-0.32332332332332336,-0.3213213213213213,-0.31931931931931934,-0.31731731731731727,-0.3153153153153153,-0.31331331331331336,-0.3113113113113113,-0.30930930930930933,-0.30730730730730726,-0.3053053053053053,-0.30330330330330335,-0.3013013013013013,-0.2992992992992993,-0.29729729729729726,-0.2952952952952953,-0.29329329329329334,-0.2912912912912913,-0.2892892892892893,-0.28728728728728725,-0.2852852852852853,-0.28328328328328334,-0.28128128128128127,-0.2792792792792793,-0.27727727727727725,-0.2752752752752753,-0.27327327327327333,-0.27127127127127126,-0.2692692692692693,-0.26726726726726724,-0.2652652652652653,-0.2632632632632632,-0.26126126126126126,-0.2592592592592593,-0.25725725725725723,-0.2552552552552553,-0.2532532532532532,-0.25125125125125125,-0.2492492492492493,-0.24724724724724723,-0.24524524524524527,-0.2432432432432432,-0.24124124124124124,-0.2392392392392393,-0.23723723723723722,-0.23523523523523526,-0.2332332332332332,-0.23123123123123124,-0.22922922922922928,-0.2272272272272272,-0.22522522522522526,-0.2232232232232232,-0.22122122122122123,-0.21921921921921927,-0.2172172172172172,-0.21521521521521525,-0.21321321321321318,-0.21121121121121122,-0.20920920920920927,-0.2072072072072072,-0.20520520520520524,-0.20320320320320318,-0.20120120120120122,-0.19919919919919926,-0.1971971971971972,-0.19519519519519524,-0.19319319319319317,-0.1911911911911912,-0.18918918918918914,-0.1871871871871872,-0.18518518518518523,-0.18318318318318316,-0.1811811811811812,-0.17917917917917914,-0.17717717717717718,-0.17517517517517522,-0.17317317317317316,-0.1711711711711712,-0.16916916916916913,-0.16716716716716717,-0.16516516516516522,-0.16316316316316315,-0.1611611611611612,-0.15915915915915912,-0.15715715715715717,-0.1551551551551552,-0.15315315315315314,-0.1511511511511512,-0.14914914914914912,-0.14714714714714716,-0.1451451451451452,-0.14314314314314314,-0.14114114114114118,-0.1391391391391391,-0.13713713713713716,-0.1351351351351351,-0.13313313313313313,-0.13113113113113117,-0.1291291291291291,-0.12712712712712715,-0.12512512512512508,-0.12312312312312312,-0.12112112112112117,-0.1191191191191191,-0.11711711711711714,-0.11511511511511507,-0.11311311311311312,-0.11111111111111116,-0.10910910910910909,-0.10710710710710714,-0.10510510510510507,-0.10310310310310311,-0.10110110110110115,-0.09909909909909909,-0.09709709709709713,-0.09509509509509506,-0.0930930930930931,-0.09109109109109115,-0.08908908908908908,-0.08708708708708712,-0.08508508508508505,-0.0830830830830831,-0.08108108108108114,-0.07907907907907907,-0.07707707707707712,-0.07507507507507505,-0.07307307307307309,-0.07107107107107113,-0.06906906906906907,-0.06706706706706711,-0.06506506506506504,-0.06306306306306309,-0.06106106106106102,-0.05905905905905906,-0.0570570570570571,-0.055055055055055035,-0.05305305305305308,-0.05105105105105101,-0.049049049049049054,-0.0470470470470471,-0.04504504504504503,-0.04304304304304307,-0.041041041041041004,-0.03903903903903905,-0.03703703703703709,-0.03503503503503502,-0.033033033033033066,-0.031031031031030998,-0.02902902902902904,-0.027027027027027084,-0.025025025025025016,-0.02302302302302306,-0.02102102102102099,-0.019019019019019034,-0.017017017017017078,-0.01501501501501501,-0.013013013013013053,-0.011011011011010985,-0.009009009009009028,-0.00700700700700696,-0.005005005005005003,-0.0030030030030030463,-0.0010010010010009784,0.0010010010010010895,0.0030030030030030463,0.005005005005005003,0.00700700700700696,0.009009009009008917,0.011011011011011096,0.013013013013013053,0.01501501501501501,0.017017017017016967,0.019019019019018923,0.021021021021021102,0.02302302302302306,0.025025025025025016,0.027027027027026973,0.02902902902902893,0.03103103103103111,0.033033033033033066,0.03503503503503502,0.03703703703703698,0.039039039039038936,0.041041041041041115,0.04304304304304307,0.04504504504504503,0.047047047047046986,0.04904904904904894,0.05105105105105112,0.05305305305305308,0.055055055055055035,0.05705705705705699,0.05905905905905895,0.06106106106106113,0.06306306306306309,0.06506506506506504,0.067067067067067,0.06906906906906896,0.07107107107107113,0.07307307307307309,0.07507507507507505,0.077077077077077,0.07907907907907896,0.08108108108108114,0.0830830830830831,0.08508508508508505,0.08708708708708701,0.08908908908908897,0.09109109109109115,0.0930930930930931,0.09509509509509506,0.09709709709709702,0.0990990990990992,0.10110110110110115,0.10310310310310311,0.10510510510510507,0.10710710710710702,0.1091091091091092,0.11111111111111116,0.11311311311311312,0.11511511511511507,0.11711711711711703,0.11911911911911921,0.12112112112112117,0.12312312312312312,0.12512512512512508,0.12712712712712704,0.12912912912912922,0.13113113113113117,0.13313313313313313,0.1351351351351351,0.13713713713713704,0.13913913913913922,0.14114114114114118,0.14314314314314314,0.1451451451451451,0.14714714714714705,0.14914914914914923,0.1511511511511512,0.15315315315315314,0.1551551551551551,0.15715715715715706,0.15915915915915924,0.1611611611611612,0.16316316316316315,0.1651651651651651,0.16716716716716706,0.16916916916916924,0.1711711711711712,0.17317317317317316,0.1751751751751751,0.17717717717717707,0.17917917917917925,0.1811811811811812,0.18318318318318316,0.18518518518518512,0.18718718718718708,0.18918918918918926,0.1911911911911912,0.19319319319319317,0.19519519519519513,0.19719719719719708,0.19919919919919926,0.20120120120120122,0.20320320320320318,0.20520520520520513,0.2072072072072071,0.20920920920920927,0.21121121121121122,0.21321321321321318,0.21521521521521514,0.21721721721721732,0.21921921921921927,0.22122122122122123,0.2232232232232232,0.22522522522522515,0.22722722722722732,0.22922922922922928,0.23123123123123124,0.2332332332332332,0.23523523523523515,0.23723723723723733,0.2392392392392393,0.24124124124124124,0.2432432432432432,0.24524524524524516,0.24724724724724734,0.2492492492492493,0.25125125125125125,0.2532532532532532,0.25525525525525516,0.25725725725725734,0.2592592592592593,0.26126126126126126,0.2632632632632632,0.26526526526526517,0.26726726726726735,0.2692692692692693,0.27127127127127126,0.2732732732732732,0.2752752752752752,0.27727727727727736,0.2792792792792793,0.28128128128128127,0.2832832832832832,0.2852852852852852,0.28728728728728736,0.2892892892892893,0.2912912912912913,0.29329329329329323,0.2952952952952952,0.29729729729729737,0.2992992992992993,0.3013013013013013,0.30330330330330324,0.3053053053053052,0.3073073073073074,0.30930930930930933,0.3113113113113113,0.31331331331331325,0.3153153153153152,0.3173173173173174,0.31931931931931934,0.3213213213213213,0.32332332332332325,0.3253253253253252,0.3273273273273274,0.32932932932932935,0.3313313313313313,0.33333333333333326,0.3353353353353352,0.3373373373373374,0.33933933933933935,0.3413413413413413,0.34334334334334327,0.3453453453453452,0.3473473473473474,0.34934934934934936,0.3513513513513513,0.35335335335335327,0.35535535535535545,0.3573573573573574,0.35935935935935936,0.3613613613613613,0.3633633633633633,0.36536536536536546,0.3673673673673674,0.36936936936936937,0.37137137137137133,0.3733733733733733,0.37537537537537546,0.3773773773773774,0.3793793793793794,0.38138138138138133,0.3833833833833833,0.38538538538538547,0.3873873873873874,0.3893893893893894,0.39139139139139134,0.3933933933933933,0.3953953953953955,0.39739739739739743,0.3993993993993994,0.40140140140140135,0.4034034034034033,0.4054054054054055,0.40740740740740744,0.4094094094094094,0.41141141141141135,0.4134134134134133,0.4154154154154155,0.41741741741741745,0.4194194194194194,0.42142142142142136,0.4234234234234233,0.4254254254254255,0.42742742742742745,0.4294294294294294,0.43143143143143137,0.4334334334334333,0.4354354354354355,0.43743743743743746,0.4394394394394394,0.4414414414414414,0.44344344344344333,0.4454454454454455,0.44744744744744747,0.4494494494494494,0.4514514514514514,0.45345345345345334,0.4554554554554555,0.4574574574574575,0.45945945945945943,0.4614614614614614,0.46346346346346334,0.4654654654654655,0.4674674674674675,0.46946946946946944,0.4714714714714714,0.47347347347347357,0.47547547547547553,0.4774774774774775,0.47947947947947944,0.4814814814814814,0.4834834834834836,0.48548548548548554,0.4874874874874875,0.48948948948948945,0.4914914914914914,0.4934934934934936,0.49549549549549554,0.4974974974974975,0.49949949949949946,0.5015015015015014,0.5035035035035036,0.5055055055055055,0.5075075075075075,0.5095095095095095,0.5115115115115114,0.5135135135135136,0.5155155155155156,0.5175175175175175,0.5195195195195195,0.5215215215215214,0.5235235235235236,0.5255255255255256,0.5275275275275275,0.5295295295295295,0.5315315315315314,0.5335335335335336,0.5355355355355356,0.5375375375375375,0.5395395395395395,0.5415415415415414,0.5435435435435436,0.5455455455455456,0.5475475475475475,0.5495495495495495,0.5515515515515514,0.5535535535535536,0.5555555555555556,0.5575575575575575,0.5595595595595595,0.5615615615615615,0.5635635635635636,0.5655655655655656,0.5675675675675675,0.5695695695695695,0.5715715715715715,0.5735735735735736,0.5755755755755756,0.5775775775775776,0.5795795795795795,0.5815815815815815,0.5835835835835836,0.5855855855855856,0.5875875875875876,0.5895895895895895,0.5915915915915915,0.5935935935935936,0.5955955955955956,0.5975975975975976,0.5995995995995995,0.6016016016016015,0.6036036036036037,0.6056056056056056,0.6076076076076076,0.6096096096096095,0.6116116116116117,0.6136136136136137,0.6156156156156156,0.6176176176176176,0.6196196196196195,0.6216216216216217,0.6236236236236237,0.6256256256256256,0.6276276276276276,0.6296296296296295,0.6316316316316317,0.6336336336336337,0.6356356356356356,0.6376376376376376,0.6396396396396395,0.6416416416416417,0.6436436436436437,0.6456456456456456,0.6476476476476476,0.6496496496496496,0.6516516516516517,0.6536536536536537,0.6556556556556556,0.6576576576576576,0.6596596596596596,0.6616616616616617,0.6636636636636637,0.6656656656656657,0.6676676676676676,0.6696696696696696,0.6716716716716717,0.6736736736736737,0.6756756756756757,0.6776776776776776,0.6796796796796796,0.6816816816816818,0.6836836836836837,0.6856856856856857,0.6876876876876876,0.6896896896896896,0.6916916916916918,0.6936936936936937,0.6956956956956957,0.6976976976976976,0.6996996996996996,0.7017017017017018,0.7037037037037037,0.7057057057057057,0.7077077077077076,0.7097097097097096,0.7117117117117118,0.7137137137137137,0.7157157157157157,0.7177177177177176,0.7197197197197196,0.7217217217217218,0.7237237237237237,0.7257257257257257,0.7277277277277276,0.7297297297297298,0.7317317317317318,0.7337337337337337,0.7357357357357357,0.7377377377377377,0.7397397397397398,0.7417417417417418,0.7437437437437437,0.7457457457457457,0.7477477477477477,0.7497497497497498,0.7517517517517518,0.7537537537537538,0.7557557557557557,0.7577577577577577,0.7597597597597598,0.7617617617617618,0.7637637637637638,0.7657657657657657,0.7677677677677677,0.7697697697697699,0.7717717717717718,0.7737737737737738,0.7757757757757757,0.7777777777777777,0.7797797797797799,0.7817817817817818,0.7837837837837838,0.7857857857857857,0.7877877877877877,0.7897897897897899,0.7917917917917918,0.7937937937937938,0.7957957957957957,0.7977977977977977,0.7997997997997999,0.8018018018018018,0.8038038038038038,0.8058058058058057,0.8078078078078077,0.8098098098098099,0.8118118118118118,0.8138138138138138,0.8158158158158157,0.8178178178178177,0.8198198198198199,0.8218218218218218,0.8238238238238238,0.8258258258258258,0.8278278278278277,0.8298298298298299,0.8318318318318318,0.8338338338338338,0.8358358358358358,0.8378378378378377,0.8398398398398399,0.8418418418418419,0.8438438438438438,0.8458458458458458,0.8478478478478477,0.8498498498498499,0.8518518518518519,0.8538538538538538,0.8558558558558558,0.8578578578578577,0.8598598598598599,0.8618618618618619,0.8638638638638638,0.8658658658658658,0.867867867867868,0.8698698698698699,0.8718718718718719,0.8738738738738738,0.8758758758758758,0.877877877877878,0.8798798798798799,0.8818818818818819,0.8838838838838838,0.8858858858858858,0.887887887887888,0.8898898898898899,0.8918918918918919,0.8938938938938938,0.8958958958958958,0.897897897897898,0.8998998998998999,0.9019019019019019,0.9039039039039038,0.9059059059059058,0.907907907907908,0.9099099099099099,0.9119119119119119,0.9139139139139139,0.9159159159159158,0.917917917917918,0.91991991991992,0.9219219219219219,0.9239239239239239,0.9259259259259258,0.927927927927928,0.92992992992993,0.9319319319319319,0.9339339339339339,0.9359359359359358,0.937937937937938,0.93993993993994,0.9419419419419419,0.9439439439439439,0.9459459459459458,0.947947947947948,0.94994994994995,0.9519519519519519,0.9539539539539539,0.9559559559559558,0.957957957957958,0.95995995995996,0.9619619619619619,0.9639639639639639,0.9659659659659658,0.967967967967968,0.96996996996997,0.9719719719719719,0.9739739739739739,0.9759759759759759,0.977977977977978,0.97997997997998,0.9819819819819819,0.9839839839839839,0.9859859859859861,0.987987987987988,0.98998998998999,0.991991991991992,0.9939939939939939,0.9959959959959961,0.997997997997998,1.0],"xaxis":"x","y":[null,-2.180960329841855,-2.031603270821881,-1.9398107669282807,-1.8724336948469076,-1.8187642990607984,-1.7739319492126995,-1.7352951754726573,-1.7012553098530705,-1.6707687767598642,-1.6431154521895799,-1.6177767900620232,-1.5943665825463134,-1.5725891921983983,-1.55221311126034,-1.5330535461580594,-1.5149605587283412,-1.4978107595269725,-1.4815013457291153,-1.4659457300845558,-1.4510702760204612,-1.4368118183464336,-1.423115752574254,-1.4099345428277787,-1.3972265426327286,-1.3849550528180474,-1.3730875613746218,-1.3615951245532503,-1.3504518587515264,-1.3396345201470274,-1.3291221544487402,-1.3188958031444211,-1.3089382556183315,-1.299233838778972,-1.2897682375653357,-1.2805283410315713,-1.2715021097439518,-1.262678461033419,-1.2540471692852042,-1.245598778953886,-1.237324528397322,-1.2292162829487827,-1.2212664759101934,-1.2134680563638631,-1.205814442875492,-1.1982994823053874,-1.190917413063924,-1.1836628322460294,-1.1765306661618091,-1.1695161438492885,-1.1626147732130836,-1.155822319481617,-1.1491347857167458,-1.1425483951447244,-1.1360595751073141,-1.1296649424573297,-1.1233612902448458,-1.1171455755590736,-1.1110149084071468,-1.1049665415251084,-1.0989978610285287,-1.0931063778207752,-1.087289719686167,-1.081545624003273,-1.0758719310206961,-1.0702665776438163,-1.0647275916864394,-1.0592530865460665,-1.0538412562657118,-1.0484903709489748,-1.0431987724983278,-1.0379648706495754,-1.032787139278023,-1.027664112954222,-1.0225943837292666,-1.0175765981314358,-1.0126094543576716,-1.007691699644857,-1.002822127807199,-0.9979995769272331,-0.9932229271890466,-0.9884910988432896,-0.9838030502944444,-0.9791577763015934,-0.9745543062846783,-0.9699917027288819,-0.9654690596803577,-0.9609855013270847,-0.9565401806590998,-0.9521322782028282,-0.9477610008246132,-0.9434255805989532,-0.9391252737372604,-0.9348593595732884,-0.9306271396016544,-0.926427936566141,-0.9222610935947069,-0.9181259733783466,-0.9140219573911535,-0.9099484451491129,-0.9059048535053389,-0.9018906159796075,-0.8979051821202019,-0.893948016896205,-0.8900186001185086,-0.8861164258879209,-0.8822410020688531,-0.8783918497871696,-0.8745685029508862,-0.8707705077924635,-0.866997422431535,-0.8632488164569889,-0.8595242705273715,-0.8558233759886525,-0.8521457345084575,-0.8484909577259148,-0.8448586669163206,-0.8412484926698724,-0.8376600745837705,-0.8340930609670139,-0.830547108557271,-0.8270218822492359,-0.823517054833906,-0.8200323067482637,-0.8165673258348609,-0.8131218071108397,-0.8096954525459455,-0.806287970849114,-0.8028990772632376,-0.7995284933677311,-0.7961759468885493,-0.7928411715153159,-0.7895239067252441,-0.786223897613547,-0.7829408947300599,-0.7796746539217864,-0.7764249361811283,-0.7731915074995392,-0.7699741387263818,-0.7667726054327583,-0.7635866877801082,-0.7604161703933748,-0.757260842238547,-0.754120496504396,-0.7509949304882411,-0.7478839454855697,-0.7447873466833627,-0.7417049430569777,-0.7386365472704396,-0.735581975580016,-0.732541047740935,-0.7295135869171301,-0.7264994195938976,-0.7234983754933394,-0.7205102874925077,-0.7175349915441226,-0.7145723265997872,-0.7116221345355913,-0.7086842600800245,-0.7057585507441063,-0.7028448567536536,-0.6999430309836063,-0.697052928894342,-0.6941744084698959,-0.6913073301580306,-0.6884515568120771,-0.6856069536344956,-0.6827733881220868,-0.6799507300127988,-0.6771388512340765,-0.6743376258526901,-0.6715469300260123,-0.668766641954664,-0.665996641836513,-0.6632368118219577,-0.6604870359704634,-0.6577472002083059,-0.6550171922874815,-0.6522969017457466,-0.6495862198677478,-0.6468850396472099,-0.6441932557501417,-0.6415107644790335,-0.638837463738008,-0.6361732529988977,-0.6335180332682222,-0.630871707055025,-0.6282341783395582,-0.6256053525427802,-0.6229851364966339,-0.6203734384151033,-0.617770167865996,-0.6151752357434546,-0.612588554241154,-0.6100100368261846,-0.6074395982135811,-0.6048771543414847,-0.6023226223469327,-0.5997759205422301,-0.5972369683919112,-0.5947056864902585,-0.5921819965393738,-0.5896658213277673,-0.5871570847094759,-0.5846557115836711,-0.5821616278747542,-0.5796747605129259,-0.5771950374152122,-0.5747223874669343,-0.5722567405036113,-0.569798027293286,-0.5673461795192544,-0.5649011297631986,-0.5624628114886978,-0.5600311590251243,-0.5576061075518985,-0.5551875930830987,-0.552775552452421,-0.5503699232984729,-0.5479706440503944,-0.5455776539137956,-0.5431908928570103,-0.5408103015976433,-0.5384358215894194,-0.5360673950093103,-0.5337049647449489,-0.5313484743823074,-0.5289978681936445,-0.526653091125706,-0.5243140887881788,-0.5219808074423916,-0.5196531939902467,-0.5173311959633916,-0.5150147615126112,-0.5127038393974432,-0.5103983789760067,-0.5080983301950452,-0.5058036435801632,-0.5035142702262775,-0.5012301617882485,-0.4989512704717096,-0.49667754902408007,-0.49440895072575486,-0.49214542938147426,-0.48988693931186555,-0.4876334353451495,-0.48538487280901355,-0.4831412075226413,-0.48090239578889976,-0.47866839438668457,-0.4764391605633995,-0.4742146520275987,-0.47199482694175665,-0.46977964391518273,-0.467569061997073,-0.4653630406696883,-0.46316153984166725,-0.4609645198414607,-0.45877194141089456,-0.45658376569884457,-0.45439995425504,-0.452220469023972,-0.45004527233892405,-0.44787432691610085,-0.4457075958488771,-0.4435450426021398,-0.4413866310067447,-0.4392323252540634,-0.43708208989063263,-0.4349358898129009,-0.43279369026206854,-0.4306554568190191,-0.4285211553993355,-0.4263907522484162,-0.4242642139366706,-0.42214150735478834,-0.42002259970911815,-0.4179074585170946,-0.41579605160276967,-0.4136883470924088,-0.4115843134101635,-0.4094839192738265,-0.40738713369064405,-0.4052939259532172,-0.4032042656354589,-0.4011181225886211,-0.39903546693740016,-0.39695626907609133,-0.39488049966481575,-0.39280812962581085,-0.3907391301397822,-0.38867347264230645,-0.3866111288203094,-0.38455207060858376,-0.3824962701863788,-0.38044369997403854,-0.37839433262968764,-0.37634814104598935,-0.37430509834693104,-0.37226517788468316,-0.3702283532364956,-0.36819459820164424,-0.3661638867984308,-0.36413619326122515,-0.36211149203755333,-0.36008975778524305,-0.3580709653695904,-0.35605508986059187,-0.35404210653020773,-0.35203199084967673,-0.3500247184868557,-0.3480202653036184,-0.3460186073532819,-0.3440197208780741,-0.3420235823066416,-0.34003016825159726,-0.33803945550709447,-0.3360514210464488,-0.3340660420197868,-0.33208329575173895,-0.33010315973915266,-0.32812561164885207,-0.3261506293154238,-0.3241781907390311,-0.3222082740832768,-0.32024085767306937,-0.31827591999254834,-0.3163134396830198,-0.3143533955409246,-0.3123957665158489,-0.3104405317085444,-0.3084876703689803,-0.30653716189444336,-0.3045889858276247,-0.3026431218547799,-0.3006995498038714,-0.29875824964276815,-0.29681920147745355,-0.29488238555025964,-0.2929477822381363,-0.291015372050923,-0.289085135629666,-0.28715705374495026,-0.285231107295242,-0.28330727730526717,-0.2813855449244134,-0.2794658914251387,-0.2775482982014153,-0.27563274676718696,-0.2737192187548423,-0.2718076959137219,-0.2698981601086316,-0.26799059331837133,-0.266084977634309,-0.2641812952589334,-0.2622795285044632,-0.26037965979144745,-0.25848167164739194,-0.2565855467054128,-0.25469126770288175,-0.2527988174801238,-0.2509081789790943,-0.24901933524209818,-0.24713226941051158,-0.24524696472352547,-0.2433634045168992,-0.2414815722217407,-0.23960145136327904,-0.23772302555967864,-0.23584627852083903,-0.23397119404724065,-0.23209775602877292,-0.23022594844360142,-0.2283557553570267,-0.22648716092037752,-0.22462014936989522,-0.2227547050256477,-0.22089081229045215,-0.2190284556487998,-0.21716761966580567,-0.21530828898616433,-0.2134504483331128,-0.2115940825074175,-0.2097391763863585,-0.2078857149227312,-0.20603368314386192,-0.20418306615063103,-0.2023338491164938,-0.20048601728654583,-0.1986395559765579,-0.1967944505720484,-0.19495068652735084,-0.19310824936470855,-0.19126712467334517,-0.18942729810859876,-0.18758875539099668,-0.18575148230540545,-0.1839154647001363,-0.1820806884861007,-0.1802471396359458,-0.17841480418320635,-0.1765836682214817,-0.17475371790358943,-0.1729249394407507,-0.17109731910178125,-0.1692708432122808,-0.16744549815383244,-0.16562127036321422,-0.16379814633161774,-0.1619761126038731,-0.16015515577766556,-0.15833526250279584,-0.1565164194804033,-0.15469861346222946,-0.15288183124987334,-0.15106605969405537,-0.14925128569387952,-0.14743749619612964,-0.14562467819452377,-0.14381281872903465,-0.1420019048851601,-0.1401919237932374,-0.13838286262774185,-0.13657470860660076,-0.13476744899051124,-0.1329610710822693,-0.13115556222608418,-0.1293509098069219,-0.1275471012498422,-0.12574412401933943,-0.1239419656186917,-0.12214061358931536,-0.12034005551012221,-0.11854027899687623,-0.11674127170157636,-0.11494302131180689,-0.11314551555013053,-0.1113487421734532,-0.10955268897243083,-0.10775734377083644,-0.10596269442495454,-0.10416872882298904,-0.10237543488446509,-0.10058280055961087,-0.09879081382879365,-0.09699946270190264,-0.09520873521780271,-0.09341861944370197,-0.09162910347462568,-0.08984017543279853,-0.08805182346710427,-0.08626403575249515,-0.08447680048944363,-0.08269010590336262,-0.08090394024407191,-0.07911829178521712,-0.07733314882371416,-0.07554849967922964,-0.07376433269360706,-0.07198063623030976,-0.07019739867391558,-0.06841460842954944,-0.06663225392235576,-0.06485032359693639,-0.06306880591687425,-0.06128768936414278,-0.05950696243860162,-0.05772661365748937,-0.05594663155484178,-0.05416700468104779,-0.05238772160226291,-0.05060877089990816,-0.048830141170167575,-0.04705182102346511,-0.045273799083945056,-0.043496063988946745,-0.04171860438852556,-0.039941408944923436,-0.03816446633205427,-0.03638776523503368,-0.03461129434961567,-0.03283504238171714,-0.031058998046937264,-0.029283150070024105,-0.02750748718441019,-0.025731998131608935,-0.023956671660900496,-0.022181496528628535,-0.020406461497872216,-0.01863155533783827,-0.0168567668233992,-0.01508208473463335,-0.013307497856301984,-0.011532994977272965,-0.009758564890232736,-0.007984196390967523,-0.006209878278068756,-0.004435599352148445,-0.0026613484157825126,-0.0008871142728607527,0.0008871142728607527,0.0026613484157825126,0.004435599352148445,0.006209878278068756,0.007984196390967523,0.009758564890232736,0.011532994977272965,0.013307497856301984,0.01508208473463335,0.0168567668233992,0.01863155533783827,0.020406461497872216,0.022181496528628535,0.023956671660900496,0.025731998131608935,0.02750748718441019,0.029283150070024105,0.031058998046937264,0.03283504238171714,0.03461129434961567,0.03638776523503368,0.03816446633205427,0.039941408944923436,0.04171860438852556,0.043496063988946745,0.045273799083945056,0.04705182102346511,0.048830141170167575,0.05060877089990816,0.05238772160226291,0.05416700468104779,0.05594663155484178,0.05772661365748937,0.05950696243860162,0.06128768936414278,0.06306880591687425,0.06485032359693639,0.06663225392235576,0.06841460842954944,0.07019739867391558,0.07198063623030976,0.07376433269360706,0.07554849967922964,0.07733314882371416,0.07911829178521712,0.08090394024407191,0.08269010590336262,0.08447680048944363,0.08626403575249515,0.08805182346710427,0.08984017543279853,0.09162910347462568,0.09341861944370197,0.09520873521780271,0.09699946270190264,0.09879081382879365,0.10058280055961087,0.10237543488446509,0.10416872882298904,0.10596269442495454,0.10775734377083644,0.10955268897243083,0.1113487421734532,0.11314551555013053,0.11494302131180689,0.11674127170157636,0.11854027899687623,0.12034005551012221,0.12214061358931536,0.1239419656186917,0.12574412401933943,0.1275471012498422,0.1293509098069219,0.13115556222608418,0.1329610710822693,0.13476744899051124,0.13657470860660076,0.13838286262774185,0.1401919237932374,0.1420019048851601,0.14381281872903465,0.14562467819452377,0.14743749619612964,0.14925128569387952,0.15106605969405537,0.15288183124987334,0.15469861346222946,0.1565164194804033,0.15833526250279584,0.16015515577766556,0.1619761126038731,0.16379814633161774,0.16562127036321422,0.16744549815383244,0.1692708432122808,0.17109731910178125,0.1729249394407507,0.17475371790358943,0.1765836682214817,0.17841480418320635,0.1802471396359458,0.1820806884861007,0.1839154647001363,0.18575148230540545,0.18758875539099668,0.18942729810859876,0.19126712467334517,0.19310824936470855,0.19495068652735084,0.1967944505720484,0.1986395559765579,0.20048601728654583,0.2023338491164938,0.20418306615063103,0.20603368314386192,0.2078857149227312,0.2097391763863585,0.2115940825074175,0.2134504483331128,0.21530828898616433,0.21716761966580567,0.2190284556487998,0.22089081229045215,0.2227547050256477,0.22462014936989522,0.22648716092037752,0.2283557553570267,0.23022594844360142,0.23209775602877292,0.23397119404724065,0.23584627852083903,0.23772302555967864,0.23960145136327904,0.2414815722217407,0.2433634045168992,0.24524696472352547,0.24713226941051158,0.24901933524209818,0.2509081789790943,0.2527988174801238,0.25469126770288175,0.2565855467054128,0.25848167164739194,0.26037965979144745,0.2622795285044632,0.2641812952589334,0.26608497763430733,0.26799059331837133,0.2698981601086316,0.2718076959137219,0.2737192187548423,0.27563274676718535,0.2775482982014153,0.2794658914251387,0.2813855449244134,0.28330727730526717,0.285231107295242,0.28715705374495026,0.28908513562966753,0.291015372050923,0.2929477822381363,0.29488238555025964,0.29681920147745355,0.29875824964276815,0.3006995498038714,0.3026431218547799,0.3045889858276247,0.30653716189444336,0.3084876703689803,0.3104405317085444,0.3123957665158489,0.3143533955409246,0.31631343968301834,0.31827591999254834,0.32024085767306937,0.3222082740832768,0.3241781907390311,0.3261506293154238,0.32812561164885207,0.33010315973915266,0.33208329575173895,0.3340660420197868,0.3360514210464488,0.33803945550709447,0.34003016825159726,0.3420235823066416,0.3440197208780741,0.3460186073532819,0.3480202653036184,0.3500247184868557,0.35203199084967673,0.35404210653020773,0.35605508986059187,0.3580709653695904,0.36008975778524305,0.36211149203755333,0.36413619326122393,0.3661638867984308,0.36819459820164424,0.3702283532364956,0.37226517788468316,0.3743050983469298,0.37634814104598935,0.37839433262968764,0.38044369997403854,0.3824962701863788,0.38455207060858376,0.3866111288203094,0.38867347264230645,0.3907391301397822,0.39280812962581085,0.39488049966481575,0.39695626907609133,0.39903546693740016,0.4011181225886211,0.4032042656354589,0.4052939259532172,0.40738713369064405,0.4094839192738265,0.4115843134101635,0.4136883470924088,0.41579605160276967,0.4179074585170946,0.42002259970911815,0.42214150735478834,0.4242642139366695,0.4263907522484162,0.4285211553993355,0.4306554568190191,0.43279369026206854,0.4349358898129009,0.43708208989063263,0.4392323252540634,0.4413866310067447,0.4435450426021398,0.4457075958488761,0.44787432691610085,0.45004527233892405,0.452220469023972,0.45439995425504,0.45658376569884457,0.45877194141089456,0.4609645198414607,0.46316153984166725,0.4653630406696883,0.467569061997073,0.46977964391518273,0.47199482694175665,0.4742146520275987,0.4764391605633995,0.47866839438668457,0.4809023957889007,0.4831412075226413,0.48538487280901355,0.4876334353451495,0.48988693931186555,0.49214542938147426,0.49440895072575486,0.49667754902408007,0.4989512704717096,0.5012301617882485,0.5035142702262775,0.5058036435801632,0.5080983301950452,0.5103983789760067,0.5127038393974432,0.5150147615126112,0.5173311959633916,0.5196531939902467,0.5219808074423916,0.5243140887881788,0.526653091125706,0.5289978681936445,0.5313484743823074,0.5337049647449489,0.5360673950093103,0.5384358215894194,0.5408103015976433,0.5431908928570103,0.5455776539137956,0.5479706440503944,0.5503699232984729,0.552775552452421,0.5551875930830987,0.5576061075518985,0.5600311590251243,0.5624628114886978,0.5649011297631986,0.5673461795192544,0.569798027293286,0.5722567405036113,0.5747223874669343,0.5771950374152122,0.5796747605129259,0.5821616278747542,0.5846557115836711,0.5871570847094759,0.5896658213277673,0.5921819965393738,0.5947056864902585,0.5972369683919104,0.5997759205422301,0.6023226223469327,0.6048771543414847,0.6074395982135804,0.6100100368261854,0.612588554241154,0.6151752357434546,0.617770167865996,0.6203734384151033,0.6229851364966347,0.6256053525427802,0.6282341783395582,0.630871707055025,0.6335180332682222,0.6361732529988985,0.638837463738008,0.6415107644790335,0.6441932557501417,0.6468850396472099,0.6495862198677478,0.6522969017457466,0.6550171922874815,0.6577472002083059,0.6604870359704628,0.6632368118219577,0.665996641836513,0.668766641954664,0.6715469300260123,0.6743376258526901,0.6771388512340765,0.6799507300127988,0.6827733881220868,0.6856069536344956,0.6884515568120771,0.6913073301580306,0.6941744084698959,0.697052928894342,0.6999430309836063,0.7028448567536529,0.7057585507441063,0.7086842600800245,0.7116221345355913,0.7145723265997872,0.7175349915441226,0.7205102874925077,0.7234983754933394,0.7264994195938976,0.7295135869171301,0.7325410477409346,0.735581975580016,0.7386365472704396,0.7417049430569777,0.7447873466833627,0.7478839454855697,0.7509949304882411,0.754120496504396,0.757260842238547,0.7604161703933748,0.7635866877801082,0.7667726054327583,0.7699741387263818,0.7731915074995392,0.7764249361811283,0.779674653921787,0.7829408947300599,0.786223897613547,0.7895239067252441,0.7928411715153159,0.7961759468885491,0.7995284933677311,0.8028990772632376,0.806287970849114,0.8096954525459455,0.81312180711084,0.8165673258348609,0.8200323067482637,0.823517054833906,0.8270218822492359,0.8305471085572715,0.8340930609670139,0.8376600745837705,0.8412484926698724,0.8448586669163203,0.848490957725915,0.8521457345084575,0.8558233759886525,0.8595242705273715,0.8632488164569887,0.866997422431535,0.8707705077924635,0.8745685029508862,0.8783918497871696,0.8822410020688529,0.8861164258879212,0.8900186001185086,0.893948016896205,0.8979051821202019,0.9018906159796075,0.9059048535053389,0.9099484451491129,0.9140219573911535,0.9181259733783466,0.9222610935947069,0.926427936566141,0.9306271396016544,0.9348593595732884,0.9391252737372604,0.9434255805989532,0.9477610008246132,0.9521322782028282,0.9565401806590998,0.9609855013270845,0.9654690596803577,0.9699917027288819,0.9745543062846783,0.9791577763015934,0.9838030502944444,0.9884910988432893,0.9932229271890466,0.9979995769272331,1.002822127807199,1.0076916996448568,1.0126094543576714,1.0175765981314358,1.0225943837292666,1.027664112954222,1.0327871392780228,1.037964870649575,1.0431987724983278,1.0484903709489748,1.0538412562657118,1.0592530865460659,1.06472759168644,1.0702665776438163,1.0758719310206961,1.081545624003273,1.0872897196861668,1.0931063778207755,1.0989978610285287,1.1049665415251084,1.1110149084071468,1.1171455755590731,1.1233612902448462,1.1296649424573297,1.1360595751073141,1.1425483951447244,1.149134785716745,1.1558223194816175,1.1626147732130836,1.1695161438492885,1.1765306661618091,1.1836628322460285,1.1909174130639242,1.1982994823053874,1.205814442875492,1.2134680563638631,1.2212664759101928,1.229216282948783,1.237324528397322,1.245598778953886,1.2540471692852042,1.2626784610334183,1.2715021097439523,1.2805283410315713,1.2897682375653357,1.2992338387789715,1.3089382556183309,1.3188958031444218,1.3291221544487402,1.3396345201470274,1.350451858751526,1.3615951245532496,1.3730875613746225,1.3849550528180474,1.3972265426327286,1.409934542827778,1.4231157525742528,1.4368118183464336,1.4510702760204612,1.4659457300845558,1.4815013457291146,1.4978107595269716,1.5149605587283412,1.5330535461580594,1.55221311126034,1.5725891921983972,1.594366582546312,1.6177767900620232,1.6431154521895799,1.6707687767598642,1.7012553098530687,1.7352951754726593,1.7739319492126995,1.8187642990607984,1.8724336948469076,1.9398107669282765,2.031603270821887,2.180960329841855,null],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"x"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"erfinv(x)"}},"legend":{"tracegroupgap":0},"margin":{"t":60}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('3715238d-8b3f-4eeb-8315-1def10226f99');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Let’s compute the MSE (ignoring inf values) between the approximation versus the torch.erfinv implementation using:</p>
<p><span class="math inline">\(a = 0.147\)</span></p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>y_rapid <span class="op">=</span> erfinv_vec(x)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>y_torch <span class="op">=</span> torch.erfinv(torch.tensor(x)).numpy()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute mask where y_rapid isn't infinite</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.isfinite(y_rapid)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>x_mask <span class="op">=</span> x[mask]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>y_rapid <span class="op">=</span> y_rapid[mask]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>y_torch <span class="op">=</span> y_torch[mask]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> np.mean((y_rapid <span class="op">-</span> y_torch) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>max_error_idx <span class="op">=</span> np.argmax(np.<span class="bu">abs</span>(y_rapid <span class="op">-</span> y_torch))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"Max Error: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">max</span>(np.<span class="bu">abs</span>(y_rapid <span class="op">-</span> y_torch))<span class="sc">}</span><span class="ss"> at x: </span><span class="sc">{</span>x_mask[max_error_idx]<span class="sc">}</span><span class="ss">, index: </span><span class="sc">{</span>max_error_idx<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_rapid: </span><span class="sc">{</span>y_rapid[max_error_idx]<span class="sc">}</span><span class="ss">, y_torch: </span><span class="sc">{</span>y_torch[max_error_idx]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 1.7424258166728075e-07
Max Error: 0.003953770269555346 at x: -0.997997997997998, index: 0
y_rapid: -2.180960329841855, y_torch: -2.1849141001114103</code></pre>
</div>
</div>
<p>Now repeat the experiment but using:</p>
<p><span class="math inline">\(a=0.140012\)</span></p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>y_rapid2 <span class="op">=</span> erfinv_vec(x, a<span class="op">=</span><span class="fl">0.140012</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>y_torch <span class="op">=</span> torch.erfinv(torch.tensor(x)).numpy()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># compute mask where y_rapid isn't infinite</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.isfinite(y_rapid2)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>x_mask <span class="op">=</span> x[mask]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>y_rapid2 <span class="op">=</span> y_rapid2[mask]</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>y_torch <span class="op">=</span> y_torch[mask]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> np.mean((y_rapid2 <span class="op">-</span> y_torch) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>max_error_idx <span class="op">=</span> np.argmax(np.<span class="bu">abs</span>(y_rapid2 <span class="op">-</span> y_torch))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max Error: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">max</span>(np.<span class="bu">abs</span>(y_rapid2 <span class="op">-</span> y_torch))<span class="sc">}</span><span class="ss"> at x: </span><span class="sc">{</span>x_mask[max_error_idx]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_rapid2: </span><span class="sc">{</span>y_rapid2[max_error_idx]<span class="sc">}</span><span class="ss">, y_torch: </span><span class="sc">{</span>y_torch[max_error_idx]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># max error index and x value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 8.462108415214081e-07
Max Error: 0.007140781441233646 at x: -0.997997997997998
y_rapid2: -2.1777733186701766, y_torch: -2.1849141001114103</code></pre>
</div>
</div>
<p>Both methods have the worst performance at around <span class="math inline">\(x=-1\)</span> which is expected since the <span class="math inline">\(\operatorname{erf}^{-1}(x)\)</span> is asymptotic at <span class="math inline">\(x=-1\)</span>. I will use <span class="math inline">\(a=0.147\)</span> for the approximation method since it has a smaller maximum error and also smaller MSE compared to the torch.erfinv implementation.</p>
</section>
<section id="pytorch-implementation" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-implementation">Pytorch Implementation</h2>
<p>Now that we have a decent approximation of the inverse error function, we can implement it in pytorch.</p>
<section id="compile-pytorch-from-source" class="level3">
<h3 class="anchored" data-anchor-id="compile-pytorch-from-source">Compile pytorch from source</h3>
<p>My experience with compiling pytorch from source was more challenging on macOS compared to Ubuntu 22.04.</p>
<p>I used this <a href="https://www.notion.so/Build-METAL-Backend-PyTorch-from-Source-359cd77337d54ce0a55c74efd9f376a5">guide</a> and in addition I encountered 2 errors that weren’t covered in the guide.</p>
<ul>
<li>I had a mismatched installation of protoc (protobuf) both from conda and brew. I had to uninstall both of them.</li>
<li>I encountered errors near the end related to cast-function-type-strict such as:</li>
</ul>
<blockquote class="blockquote">
<p>/src/pytorch/torch/csrc/Generator.cpp /src/pytorch/torch/csrc/Generator.cpp:208:16: error: cast from ‘PyObject <em>(</em>)(THPGenerator <em>, void </em>)’ (aka ’_object <em>(</em>)(THPGenerator <em>, void </em>)‘) to ’getter’ (aka ’_object <em>(</em>)(_object <em>, void </em>)’) converts to incompatible function type [-Werror,-Wcast-function-type-strict] {“device”, (getter)THPGenerator_get_device, nullptr, nullptr, nullptr},</p>
</blockquote>
<p>I had to modify <a href="https://github.com/pytorch/pytorch/blob/07314206455bee8b3b531069056e4cb229913887/CMakeLists.txt#L893">CMakeLists.txt</a>to to comment out : -Werror=cast-function-type” CMAKE_CXX_FLAGS</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>append_cxx_flag_if_supported(<span class="st">"-Wno-unused-but-set-variable"</span> CMAKE_CXX_FLAGS)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>append_cxx_flag_if_supported(<span class="st">"-Wno-maybe-uninitialized"</span> CMAKE_CXX_FLAGS)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>string(APPEND CMAKE_CXX_FLAGS_DEBUG <span class="st">" -fno-omit-frame-pointer -O0"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>string(APPEND CMAKE_LINKER_FLAGS_DEBUG <span class="st">" -fno-omit-frame-pointer -O0"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>append_cxx_flag_if_supported(<span class="st">"-fno-math-errno"</span> CMAKE_CXX_FLAGS)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>append_cxx_flag_if_supported(<span class="st">"-fno-trapping-math"</span> CMAKE_CXX_FLAGS)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>append_cxx_flag_if_supported(<span class="st">"-Werror=format"</span> CMAKE_CXX_FLAGS)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># append_cxx_flag_if_supported("-Werror=cast-function-type" CMAKE_CXX_FLAGS)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then finally I was able to compile pytorch from source. using the follow command:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="va">MACOSX_DEPLOYMENT_TARGET</span><span class="op">=</span>13.0 <span class="va">CC</span><span class="op">=</span>clang <span class="va">CXX</span><span class="op">=</span>clang++ <span class="va">USE_MPS</span><span class="op">=</span>1 <span class="va">USE_PYTORCH_METAL</span><span class="op">=</span>1 <span class="ex">\\</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="va">DEBUG</span><span class="op">=</span>1 <span class="ex">python</span> setup.py develop</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="metal-api" class="level2">
<h2 class="anchored" data-anchor-id="metal-api">Metal api</h2>
<ul>
<li>https://developer.apple.com/documentation/metalperformanceshadersgraph/mpsgraph</li>
</ul>
<section id="reducing-the-mpsgraph-code" class="level3">
<h3 class="anchored" data-anchor-id="reducing-the-mpsgraph-code">Reducing the MPSGraph code</h3>
<p>First I have to try to reduce <a href="#eq-eq3">Equation&nbsp;3</a> to avoid repeated calculation of terms in order to reduce the number of nodes in the compute graph.</p>
<p>We can create the following terms so that they are re-used in the graph:</p>
<p><span class="math display">\[\begin{align*}
A &amp;= x^2 \\
B &amp;= \log(1 - A) \\
C &amp;= \frac{2}{\pi a} + \frac{B}{2} \\
\end{align*}\]</span></p>
<p>Then the <a href="#eq-eq3">Equation&nbsp;3</a> can be re-written as: <span class="math display">\[
\operatorname{erfinv}(x) = \operatorname{sgn}(x) \sqrt{\sqrt{C^2 - \frac{B}{a}} - C}
\]</span></p>
<ul>
<li><span class="math inline">\(A\)</span> term requires 1 multiply node</li>
<li><span class="math inline">\(B\)</span> term requires 1 log node and 1 subtract node</li>
<li><span class="math inline">\(C\)</span> term requires 1 add node, 2 divisision nodes, 1 multiply node</li>
<li><span class="math inline">\(\operatorname{erfinv}(x)\)</span> requires 2 square root nodes, 2 subtract nodes, 1 multiply node, 1 division node
<ul>
<li>the <span class="math inline">\(\operatorname{sgn}(x)\)</span> term requires 4 nodes: greaterThan, selectPredicate, 2 multiply nodes</li>
</ul></li>
</ul>
<p>This translate to a total of 17 nodes (not counting constants) in the compute graph for the erfinv function.</p>
</section>
<section id="mpsgraph-implementation" class="level3">
<h3 class="anchored" data-anchor-id="mpsgraph-implementation">MPSGraph implementation</h3>
<pre class="objc"><code>// constant tensors
auto negOneTensor = [mpsGraph constantWithScalar:-1.0 dataType:inputTensor.dataType];
auto zeroTensor = [mpsGraph constantWithScalar:0.0 dataType:inputTensor.dataType];
auto halfTensor = [mpsGraph constantWithScalar:0.5 dataType:inputTensor.dataType];
auto oneTensor = [mpsGraph constantWithScalar:1.0 dataType:inputTensor.dataType];
auto twoTensor = [mpsGraph constantWithScalar:2.0 dataType:inputTensor.dataType];
auto piTensor = [mpsGraph constantWithScalar:3.14159265358979323846264338327950288 dataType:inputTensor.dataType];
auto aTensor = [mpsGraph constantWithScalar:0.147 dataType:inputTensor.dataType];


auto A = [mpsGraph multiplicationWithPrimaryTensor:inputTensor secondaryTensor:inputTensor name:nil];
auto B = [mpsGraph logarithmWithTensor:[mpsGraph subtractionWithPrimaryTensor:oneTensor
                                                                    secondaryTensor:A
                                                                                name:nil]
                                        name:nil];
auto C = [mpsGraph
    additionWithPrimaryTensor:[mpsGraph divisionWithPrimaryTensor:twoTensor
                                                    secondaryTensor:[mpsGraph multiplicationWithPrimaryTensor:piTensor
                                                                                            secondaryTensor:aTensor
                                                                                                        name:nil]
                                                                name:nil]
                secondaryTensor:[mpsGraph multiplicationWithPrimaryTensor:B secondaryTensor:halfTensor name:nil]
                            name:nil];
auto CSquared = [mpsGraph multiplicationWithPrimaryTensor:C secondaryTensor:C name:nil];
auto CSquaredMinusBDivA = [mpsGraph subtractionWithPrimaryTensor:CSquared
                                        secondaryTensor:[mpsGraph divisionWithPrimaryTensor:B
                                                                            secondaryTensor:aTensor
                                                                                        name:nil]
                                                    name:nil];
auto squareRootDiffTerm = [mpsGraph squareRootWithTensor:CSquaredMinusBDivA name:nil];
auto finalDiff = [mpsGraph subtractionWithPrimaryTensor:squareRootDiffTerm secondaryTensor:C name:nil];
auto finalSquareRoot = [mpsGraph squareRootWithTensor:finalDiff name:nil];
auto predicateTensor = [mpsGraph greaterThanOrEqualToWithPrimaryTensor:inputTensor
                                                        secondaryTensor:zeroTensor
                                                                    name:nil];
auto resultPositive = [mpsGraph multiplicationWithPrimaryTensor:finalSquareRoot secondaryTensor:oneTensor name:nil];
auto resultNegative = [mpsGraph multiplicationWithPrimaryTensor:finalSquareRoot
                                                secondaryTensor:negOneTensor
                                                            name:nil];
return [mpsGraph selectWithPredicateTensor:predicateTensor
                        truePredicateTensor:resultPositive
                        falsePredicateTensor:resultNegative
                                        name:nil];
</code></pre>
<p>Here’s a quick benchmark of the MPS compute (M1 macbookpro 16” 16 GB) vs CPU for the erfinv function:</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.00001</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(<span class="st">"mps"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># measure MPS compute time</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>time <span class="op">=</span> <span class="op">%</span>timeit <span class="op">-</span>o <span class="op">-</span>q  torch.erfinv(x)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>mps_time <span class="op">=</span> time.average</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MPS torch.erfinv time: "</span>, mps_time)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(<span class="st">"cpu"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># measure CPU compute time by calling torch.erfinv but storing it to y_cpu</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>time <span class="op">=</span> <span class="op">%</span>timeit <span class="op">-</span>o <span class="op">-</span>q torch.erfinv(x)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>cpu_time <span class="op">=</span> time.average</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CPU torch.erfinv time: "</span>, cpu_time)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MPS torch.erfinv is </span><span class="sc">{</span>cpu_time<span class="op">/</span>mps_time<span class="op">*</span><span class="dv">100</span><span class="sc">}</span><span class="ss"> percent faster than CPU torch.erfinv"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># compute MSE between y_cpu and y_mps</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(<span class="st">"mps"</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>y_mps <span class="op">=</span> torch.erfinv(x)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>y_cpu <span class="op">=</span> torch.erfinv(x.to(<span class="st">"cpu"</span>))</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> torch.isfinite(y_cpu) <span class="op">&amp;</span> torch.isfinite(y_mps.to(<span class="st">"cpu"</span>))</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> torch.square(y_cpu[mask] <span class="op">-</span> y_mps[mask].to(<span class="st">"cpu"</span>)).mean()</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE between MPS and CPU torch.erfinv: "</span>, mse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MPS torch.erfinv time:  1.1875705477141309e-05
CPU torch.erfinv time:  0.004062085178572618
MPS torch.erfinv is 34205.001011446715 percent faster than CPU torch.erfinv
MSE between MPS and CPU torch.erfinv:  tensor(4.1653e-14)</code></pre>
</div>
</div>
<p>I thought I was done until I added erfinv into those 2 test cases.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> test/test_mps.py TestNLLLoss.test_unary_ops</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> test/test_unary_ufuncs.py TestUnaryUfuncs.unary_mem_overlap_cases</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>I found that the metal compute graph accuracy was not good enough to pass the test for TestNLLLoss.test_unary_ops where it could only pass 70% of the test. I ended up adding 2 processing step to include: - 2 iterations of the Newton-Raphson method to improve the accuracy of the MPS compute graph. - Logic to set to +/- inf if input is +/- 1.0 since the approximation be off at the boundary.</p>
<p>Below was the addition to the MPSGraph unary compute graph for erfinv:</p>
<pre class="objc"><code>   // add 2 steps of Newton-Raphson iteration to improve accuracy
    // adopted from
    // https://github.com/pytorch/pytorch/blob/4154c8ea159fdaecc71ee9af820ac956193c875b/aten/src/ATen/native/Math.h#L191

    auto currentEstimated = estimated;
    for (int i = 0; i &lt; 2; ++i) {
      auto negEstimated = [mpsGraph multiplicationWithPrimaryTensor:currentEstimated
                                                    secondaryTensor:negOneTensor
                                                               name:nil];
      auto estimatedSquared = [mpsGraph multiplicationWithPrimaryTensor:negEstimated
                                                        secondaryTensor:currentEstimated
                                                                   name:nil];
      auto estimatedSquaredExp = [mpsGraph exponentWithTensor:estimatedSquared name:nil];
      auto twoDivSquareRootPi = [mpsGraph divisionWithPrimaryTensor:twoTensor
                                                    secondaryTensor:piSquareRootTensor
                                                               name:nil];
      auto gradientDenominator = [mpsGraph multiplicationWithPrimaryTensor:twoDivSquareRootPi
                                                           secondaryTensor:estimatedSquaredExp
                                                                      name:nil];
      auto changeErf = [mpsGraph subtractionWithPrimaryTensor:[mpsGraph erfWithTensor:currentEstimated name:nil]
                                              secondaryTensor:inputTensor
                                                         name:nil];
      auto gradient = [mpsGraph divisionWithPrimaryTensor:changeErf secondaryTensor:gradientDenominator name:nil];
      currentEstimated = [mpsGraph subtractionWithPrimaryTensor:currentEstimated secondaryTensor:gradient name:nil];
    }

    // post processing step to check if we have exactly +1/-1 then we should map to infinity/-infinity
    // this is because the this algorithm might push us on the wrong side of the asymptote due to rounding
    auto onePredicate = [mpsGraph equalWithPrimaryTensor:inputTensor secondaryTensor:oneTensor name:nil];
    auto negOnePredicate = [mpsGraph equalWithPrimaryTensor:inputTensor secondaryTensor:negOneTensor name:nil];

    auto resultWithInfinity = [mpsGraph selectWithPredicateTensor:onePredicate
                                              truePredicateTensor:infinityTensor
                                             falsePredicateTensor:currentEstimated
                                                             name:nil];
    return [mpsGraph selectWithPredicateTensor:negOnePredicate
                           truePredicateTensor:negInfinityTensor
                          falsePredicateTensor:resultWithInfinity
                                          name:nil];</code></pre>
<p>Adding the above code allows me to pass the pytorch automatic testing 100%.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="ex">➜</span> python3 test/test_mps.py TestNLLLoss.test_unary_ops</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">.</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="ex">----------------------------------------------------------------------</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Ran</span> 1 test in 0.283s</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="ex">OK2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Unfortunately, I discovered that the current algorithm uses too much memory. I have to optimize the MPS compute graph further before this function could be of practical use. I will go back and update this blog and reopen my PR once I have a better solution.</p>
<p>** UPDATE July 19, 2023 ** I had created another <a href="https://github.com/pytorch/pytorch/pull/101507">PR</a> where I used raw metal kernel for 18x speed up instead of the MPS graph api. This PR is currently under review.</p>
<p>** UPDATE Aug 16, 2023 ** The raw metal <a href="https://github.com/pytorch/pytorch/pull/101507">PR</a> was merged into pytorch master. The code has a minor bug that would cause slicing to fail so I submitted another follow up <a href="https://github.com/pytorch/pytorch/pull/105801">PR</a> for the bug fix.</p>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-educare_error_in_functions" class="csl-entry" role="listitem">
1. <span class="smallcaps">EduCare</span>. 2023. Error in functions. <a href="https://www.educare.bz/unit/error-in-functions/">https://www.educare.bz/unit/error-in-functions/</a>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>